{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnAutoencoder(nn.Module):\n",
    "    def __init__(self, scale=2, channel_maps=[], padding=1, kernel_size=3, num_channels=3, img_width=100, img_height=100, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.img_width      = img_width\n",
    "        self.img_height     = img_height\n",
    "        self.num_channels   = num_channels\n",
    "        self.kernel_size    = kernel_size\n",
    "        self.padding        = padding\n",
    "        self.channel_maps   = channel_maps\n",
    "        self.scale          = scale\n",
    "\n",
    "        self.reversed_channel_maps = list(reversed(channel_maps))\n",
    "\n",
    "        # Build convolutional layers\n",
    "        self.convolutional_layers = nn.ModuleList([])\n",
    "\n",
    "        # [3, 16, 4, 8, 4, 8, 8, 4, 8]\n",
    "        for i in range(len(self.channel_maps) - 1):\n",
    "            self.convolutional_layers.append(nn.Conv2d(self.channel_maps[i], self.channel_maps[i+1], kernel_size=self.kernel_size, padding=self.padding))\n",
    "\n",
    "        # Build deconvolutional layers\n",
    "        self.deconvolutional_layers = nn.ModuleList([])\n",
    "\n",
    "        for i in range(len(self.reversed_channel_maps) - 1):\n",
    "            self.deconvolutional_layers.append(nn.ConvTranspose2d(self.reversed_channel_maps[i], self.reversed_channel_maps[i+1], 2, stride=2))\n",
    "\n",
    "    def conv(self, x):\n",
    "        for i in range(len(self.convolutional_layers)):\n",
    "            conv_layer = self.convolutional_layers[i]\n",
    "\n",
    "            x = F.max_pool2d(F.relu(conv_layer(x)), self.scale)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def compress(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def deconv(self, x):\n",
    "        for i in range(len(self.deconvolutional_layers)):\n",
    "            deconv_layer = self.deconvolutional_layers[i]\n",
    "            x = deconv_layer(x)\n",
    "\n",
    "            if i != len(self.deconvolutional_layers) - 1:\n",
    "                x = F.relu(x)\n",
    "            else:\n",
    "                x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.deconv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31eeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnAutoencoderDataset(Dataset):\n",
    "    def __init__(self, img_dir, img_width, img_height):\n",
    "        self.img_dir    = img_dir\n",
    "        self.img_width  = img_width\n",
    "        self.img_height = img_height\n",
    "        self.images     = os.listdir(img_dir)\n",
    "\n",
    "        self.dim = (img_width, img_height)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.images[index])\n",
    "\n",
    "        img = (cv2.resize(cv2.imread(img_path), self.dim) / 255).transpose((2, 0, 1)) \n",
    "\n",
    "        # Input is the Output\n",
    "        return torch.Tensor(img), torch.Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fc6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data    = data.float().to(device=device)\n",
    "        targets = targets.float().to(device=device)\n",
    "\n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "    ave_loss = ave_loss / count\n",
    "\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca69b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device         = 'cuda'\n",
    "gpu_index      = 0\n",
    "epochs         = 100\n",
    "learning_rate  = 0.0001\n",
    "chunk_size     = 1\n",
    "batch_size     = 1\n",
    "cont           = False\n",
    "kernel_size    = 3\n",
    "model_file     = \"cnn-model.pth\"\n",
    "output_file    = \"data.csv\"\n",
    "channel_maps   = [3, 16, 8, 4]\n",
    "padding        = 1\n",
    "scale          = 2\n",
    "img_width      = 128\n",
    "img_height     = 128\n",
    "train_img_dir  = \"/home/ralampay/Desktop/training/Male\"\n",
    "num_channels   = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    print(\"CUDA Device: {}\".format(torch.cuda.get_device_name(gpu_index)))\n",
    "    device = \"cuda:{}\".format(gpu_index)\n",
    "    \n",
    "model = CnnAutoencoder(\n",
    "    scale=scale,\n",
    "    channel_maps=channel_maps,\n",
    "    padding=padding,\n",
    "    kernel_size=kernel_size,\n",
    "    num_channels=num_channels,\n",
    "    img_width=img_width,\n",
    "    img_height=img_height\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c170550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cont:\n",
    "    print(\"Loading model from {}\".format(model_file))\n",
    "    state = torch.load(model_file)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    model.optimizer = state['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b213b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CnnAutoencoderDataset(\n",
    "    img_dir=train_img_dir,\n",
    "    img_width=img_width,\n",
    "    img_height=img_height\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    ave_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    losses.append(ave_loss)\n",
    "\n",
    "    # Save model after every epoch\n",
    "    print(\"Saving model to {}...\".format(model_file))\n",
    "\n",
    "    state = {\n",
    "        'state_dict':   model.state_dict(),\n",
    "        'optimizer':    optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(state, model_file)\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d361da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = pd.Series(losses)\n",
    "df_loss.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f41b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
