{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e0e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608cc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnAutoencoder(nn.Module):\n",
    "    def __init__(self, scale=2, channel_maps=[], padding=1, kernel_size=3, num_channels=3, img_width=100, img_height=100, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.img_width      = img_width\n",
    "        self.img_height     = img_height\n",
    "        self.num_channels   = num_channels\n",
    "        self.kernel_size    = kernel_size\n",
    "        self.padding        = padding\n",
    "        self.channel_maps   = channel_maps\n",
    "        self.scale          = scale\n",
    "\n",
    "        self.reversed_channel_maps = list(reversed(channel_maps))\n",
    "\n",
    "        # Build convolutional layers\n",
    "        self.convolutional_layers = nn.ModuleList([])\n",
    "\n",
    "        for i in range(len(self.channel_maps) - 1):\n",
    "            self.convolutional_layers.append(nn.Conv2d(self.channel_maps[i], self.channel_maps[i+1], kernel_size=self.kernel_size, padding=self.padding))\n",
    "\n",
    "        # Build deconvolutional layers\n",
    "        self.deconvolutional_layers = nn.ModuleList([])\n",
    "\n",
    "        for i in range(len(self.reversed_channel_maps) - 1):\n",
    "            self.deconvolutional_layers.append(nn.ConvTranspose2d(self.reversed_channel_maps[i], self.reversed_channel_maps[i+1], 2, stride=2))\n",
    "\n",
    "    def conv(self, x):\n",
    "        for i in range(len(self.convolutional_layers)):\n",
    "            conv_layer = self.convolutional_layers[i]\n",
    "\n",
    "            x = F.max_pool2d(F.relu(conv_layer(x)), self.scale)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def compress(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def deconv(self, x):\n",
    "        for i in range(len(self.deconvolutional_layers)):\n",
    "            deconv_layer = self.deconvolutional_layers[i]\n",
    "            x = deconv_layer(x)\n",
    "\n",
    "            if i != len(self.deconvolutional_layers) - 1:\n",
    "                x = F.relu(x)\n",
    "            else:\n",
    "                x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.deconv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31eeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnAutoencoderDataset(Dataset):\n",
    "    def __init__(self, img_dir, img_width, img_height):\n",
    "        self.img_dir    = img_dir\n",
    "        self.img_width  = img_width\n",
    "        self.img_height = img_height\n",
    "        self.images     = os.listdir(img_dir)\n",
    "\n",
    "        self.dim = (img_width, img_height)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.images[index])\n",
    "\n",
    "        img = (cv2.resize(cv2.imread(img_path), self.dim) / 255).transpose((2, 0, 1)) \n",
    "\n",
    "        # Input is the Output\n",
    "        return torch.Tensor(img), torch.Tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aca69b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device         = 'cuda'\n",
    "gpu_index      = 0\n",
    "chunk_size     = 1\n",
    "batch_size     = 1\n",
    "cont           = False\n",
    "kernel_size    = 3\n",
    "model_file     = \"cnn-model.pth\"\n",
    "output_file    = \"data.csv\"\n",
    "channel_maps   = [3, 16, 8, 4]\n",
    "padding        = 1\n",
    "scale          = 2\n",
    "img_width      = 128\n",
    "img_height     = 128\n",
    "img_dir        = \"/home/ralampay/Desktop/training/Male\"\n",
    "num_channels   = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9401fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if device == 'cuda':\n",
    "    print(\"CUDA Device: {}\".format(torch.cuda.get_device_name(gpu_index)))\n",
    "    device = \"cuda:{}\".format(gpu_index)\n",
    "    \n",
    "model = CnnAutoencoder(\n",
    "    scale=scale,\n",
    "    channel_maps=channel_maps,\n",
    "    padding=padding,\n",
    "    kernel_size=kernel_size,\n",
    "    num_channels=num_channels,\n",
    "    img_width=img_width,\n",
    "    img_height=img_height\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c170550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from cnn-model.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model from {}\".format(model_file))\n",
    "state = torch.load(model_file)\n",
    "model.load_state_dict(state['state_dict'])\n",
    "model.optimizer = state['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b213b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CnnAutoencoderDataset(\n",
    "    img_dir=img_dir,\n",
    "    img_width=img_width,\n",
    "    img_height=img_height\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ecb6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Size: 1024\n",
      "Normalizing...\n",
      "Writing to file data.csv\n"
     ]
    }
   ],
   "source": [
    "raw_data = []\n",
    "\n",
    "for batch_idx, (data, targets) in enumerate(loader):\n",
    "    data = data.float().to(device=device)\n",
    "    compressed_data = model.compress(data)\n",
    "    \n",
    "    for item in compressed_data:\n",
    "        vector = item.detach().cpu().numpy().astype(np.float32)\n",
    "        raw_data.append(vector)\n",
    "        \n",
    "columns = []\n",
    "\n",
    "for i in range(len(raw_data[0])):\n",
    "    columns.append(\"x{}\".format(i))\n",
    "    \n",
    "df_x = pd.DataFrame(raw_data, columns=columns)\n",
    "\n",
    "print(\"Latent Size: {}\".format(len(columns)))\n",
    "\n",
    "print(\"Normalizing...\")\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x_scaled = min_max_scaler.fit_transform(df_x.values)\n",
    "\n",
    "df_x = pd.DataFrame(x_scaled, columns=columns)\n",
    "\n",
    "print(\"Writing to file {}\".format(output_file))\n",
    "df_x.to_csv(output_file, index=False, header=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad0214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
