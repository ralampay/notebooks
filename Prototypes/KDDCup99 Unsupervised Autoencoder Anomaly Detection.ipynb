{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6df3849",
   "metadata": {},
   "source": [
    "## Unsupervised Autoencoder Anomaly Detection\n",
    "\n",
    "1. Train an autoencoder to capture latent representation of entire dataset\n",
    "2. Extract the latent representation of the entire dataset\n",
    "3. Append the reconstruction error as part of the feature vector for the latent representation dataset\n",
    "4. Perform clustering against the new dataset to determine natural groupings\n",
    "5. Train another autoencoder against datapoints within groupings treated as normal\n",
    "6. Apply autothresholding with head tail break\n",
    "7. Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c0a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.stats import iqr\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('..')\n",
    "\n",
    "from lib.autoencoder import Autoencoder\n",
    "from lib.autoencoder_dataset import AutoencoderDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485132ff",
   "metadata": {},
   "source": [
    "## Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f3f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label column\n",
    "label_column = 'y'\n",
    "\n",
    "ds_train_file = \"../Datasets/kddcup99_train.csv\"\n",
    "ds_test_file = \"../Datasets/kddcup99_test.csv\"\n",
    "\n",
    "# Dataframe instance for training data\n",
    "df_train = pd.read_csv(ds_train_file)\n",
    "# Dataframe instance for test data\n",
    "df_test = pd.read_csv(ds_test_file)\n",
    "\n",
    "# Expected number of features\n",
    "n_features = 40\n",
    "\n",
    "# Extracted dataframe for all training values without labels\n",
    "df_train_x = df_train.drop([label_column], axis=1)\n",
    "# Extracted dataframe for all labels of training data\n",
    "df_train_y = df_train[label_column]\n",
    "\n",
    "# Extracted dataframe for all test values without labels\n",
    "df_test_x = df_test.drop(['y'], axis=1)\n",
    "# Extracted dataframe for all test labels of testing data\n",
    "df_test_y = df_test['y']\n",
    "\n",
    "# Autoencoder parameter for layers. First element is the size of the input vector. Succeeding values are hidden layers for the encoder\n",
    "layers = [40, 30]\n",
    "\n",
    "# Autoencoder parameter for hidden activation\n",
    "h_activation = 'relu'\n",
    "\n",
    "# Autoencoder parameter for output activation\n",
    "o_activation = 'sigmoid'\n",
    "\n",
    "# Autoencoder parameter for learning rate\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# Torch parameter for device\n",
    "device = 'cpu'\n",
    "\n",
    "# Training parameter for number of epochs\n",
    "epochs = 20\n",
    "\n",
    "# Training parameter for batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# DBSCAN parameter eps\n",
    "eps = 0.04\n",
    "\n",
    "# DBSCAN parameter minimum samples\n",
    "min_samples = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e575bf6",
   "metadata": {},
   "source": [
    "## Train Autoencoder Model\n",
    "\n",
    "The first autoencoder will attempt to get the latent representation of the data regardless of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c516380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/4601 [00:00<?, ?it/s]/home/ralampay/workspace/notebooks/env/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  Variable._execution_engine.run_backward(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:12<00:00, 358.52it/s, loss=0.237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:11<00:00, 389.06it/s, loss=0.233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:18<00:00, 253.94it/s, loss=0.228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:16<00:00, 271.31it/s, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:15<00:00, 290.86it/s, loss=0.217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:15<00:00, 291.41it/s, loss=0.211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:11<00:00, 409.47it/s, loss=0.204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:11<00:00, 401.96it/s, loss=0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:10<00:00, 437.53it/s, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:12<00:00, 362.62it/s, loss=0.179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:11<00:00, 409.38it/s, loss=0.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:12<00:00, 374.15it/s, loss=0.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:11<00:00, 386.17it/s, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:12<00:00, 367.61it/s, loss=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:13<00:00, 336.98it/s, loss=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:12<00:00, 357.58it/s, loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:12<00:00, 373.20it/s, loss=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:10<00:00, 425.24it/s, loss=0.101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:11<00:00, 394.43it/s, loss=0.0911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4601/4601 [00:13<00:00, 347.32it/s, loss=0.0818]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(layers=layers, h_activation=h_activation, o_activation=o_activation, device=device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Represent the training data as x\n",
    "x = torch.tensor(df_train_x.values).float().to(device)\n",
    "\n",
    "# Load the dataset\n",
    "train_ds = AutoencoderDataset(x=x)\n",
    "\n",
    "# Create a DataLoader instance\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# The training process\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    loop = tqdm(train_loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Feed forward\n",
    "        predictions = model(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac609821",
   "metadata": {},
   "source": [
    "## Compression\n",
    "\n",
    "Using the trained autoencoder, compress the data to latent space and create a new data frame containing latent vectors and reconstruction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a7a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793240</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363471</td>\n",
       "      <td>0.541753</td>\n",
       "      <td>0.406474</td>\n",
       "      <td>0.277373</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483487</td>\n",
       "      <td>0.454220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244190</td>\n",
       "      <td>0.302358</td>\n",
       "      <td>0.322059</td>\n",
       "      <td>5.236656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788108</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.366993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.087326</td>\n",
       "      <td>0.286169</td>\n",
       "      <td>0.316868</td>\n",
       "      <td>0.397639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648108</td>\n",
       "      <td>0.267519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140804</td>\n",
       "      <td>0.198607</td>\n",
       "      <td>0.243114</td>\n",
       "      <td>0.317519</td>\n",
       "      <td>5.431109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.455536</td>\n",
       "      <td>0.148629</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>0.189248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.228299</td>\n",
       "      <td>0.402206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219753</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.147582</td>\n",
       "      <td>0.272677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367231</td>\n",
       "      <td>0.310925</td>\n",
       "      <td>0.305324</td>\n",
       "      <td>6.148790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.241962</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>0.110588</td>\n",
       "      <td>0.526672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318677</td>\n",
       "      <td>0.788280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536704</td>\n",
       "      <td>0.358023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321377</td>\n",
       "      <td>0.034238</td>\n",
       "      <td>0.490966</td>\n",
       "      <td>0.562130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487425</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>0.529104</td>\n",
       "      <td>4.761903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251684</td>\n",
       "      <td>0.698637</td>\n",
       "      <td>0.134919</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325630</td>\n",
       "      <td>0.769554</td>\n",
       "      <td>0.982958</td>\n",
       "      <td>0.532264</td>\n",
       "      <td>0.341555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331272</td>\n",
       "      <td>0.039653</td>\n",
       "      <td>0.476847</td>\n",
       "      <td>0.547436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485895</td>\n",
       "      <td>0.159511</td>\n",
       "      <td>0.516632</td>\n",
       "      <td>4.721280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46004</th>\n",
       "      <td>0.650656</td>\n",
       "      <td>0.798774</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526098</td>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.646661</td>\n",
       "      <td>0.584388</td>\n",
       "      <td>0.662517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475805</td>\n",
       "      <td>0.387673</td>\n",
       "      <td>0.514687</td>\n",
       "      <td>0.576287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342431</td>\n",
       "      <td>0.292779</td>\n",
       "      <td>0.382569</td>\n",
       "      <td>3.738620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>0.592062</td>\n",
       "      <td>0.566196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.426163</td>\n",
       "      <td>0.583065</td>\n",
       "      <td>0.668464</td>\n",
       "      <td>0.650636</td>\n",
       "      <td>0.541520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757745</td>\n",
       "      <td>0.107177</td>\n",
       "      <td>0.721660</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537675</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>0.697988</td>\n",
       "      <td>3.176559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46006</th>\n",
       "      <td>0.689835</td>\n",
       "      <td>0.706366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476489</td>\n",
       "      <td>0.594329</td>\n",
       "      <td>0.656055</td>\n",
       "      <td>0.717538</td>\n",
       "      <td>0.695643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571234</td>\n",
       "      <td>0.285999</td>\n",
       "      <td>0.706444</td>\n",
       "      <td>0.751561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480430</td>\n",
       "      <td>0.144457</td>\n",
       "      <td>0.659397</td>\n",
       "      <td>3.020452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46007</th>\n",
       "      <td>0.592263</td>\n",
       "      <td>0.538188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467956</td>\n",
       "      <td>0.565733</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.662287</td>\n",
       "      <td>0.543637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820098</td>\n",
       "      <td>0.137484</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.734681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578817</td>\n",
       "      <td>0.083559</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>3.245474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46008</th>\n",
       "      <td>0.611027</td>\n",
       "      <td>0.554694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487942</td>\n",
       "      <td>0.566152</td>\n",
       "      <td>0.690495</td>\n",
       "      <td>0.678824</td>\n",
       "      <td>0.570753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798789</td>\n",
       "      <td>0.180341</td>\n",
       "      <td>0.777929</td>\n",
       "      <td>0.751657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582078</td>\n",
       "      <td>0.113273</td>\n",
       "      <td>0.723377</td>\n",
       "      <td>3.131653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46009 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3   x4        x5        x6  \\\n",
       "0      0.793240  0.826811  0.000000  0.634476  0.0  0.363471  0.541753   \n",
       "1      0.788108  0.362938  0.161218  0.366993  0.0  0.389249  0.087326   \n",
       "2      0.455536  0.148629  0.055008  0.189248  0.0  0.283654  0.228299   \n",
       "3      0.241962  0.711267  0.110588  0.526672  0.0  0.318677  0.788280   \n",
       "4      0.251684  0.698637  0.134919  0.529032  0.0  0.325630  0.769554   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "46004  0.650656  0.798774  0.062688  0.319400  0.0  0.526098  0.499348   \n",
       "46005  0.592062  0.566196  0.000000  0.174644  0.0  0.426163  0.583065   \n",
       "46006  0.689835  0.706366  0.000000  0.388670  0.0  0.476489  0.594329   \n",
       "46007  0.592263  0.538188  0.000000  0.193895  0.0  0.467956  0.565733   \n",
       "46008  0.611027  0.554694  0.000000  0.240257  0.0  0.487942  0.566152   \n",
       "\n",
       "             x7        x8        x9  ...       x21       x22       x23  \\\n",
       "0      0.406474  0.277373  0.465755  ...  0.000000  0.000000  0.483487   \n",
       "1      0.286169  0.316868  0.397639  ...  0.347521  0.000000  0.648108   \n",
       "2      0.402206  0.000000  0.109701  ...  0.219753  0.014701  0.147582   \n",
       "3      1.000000  0.536704  0.358023  ...  0.321377  0.034238  0.490966   \n",
       "4      0.982958  0.532264  0.341555  ...  0.331272  0.039653  0.476847   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "46004  0.646661  0.584388  0.662517  ...  0.475805  0.387673  0.514687   \n",
       "46005  0.668464  0.650636  0.541520  ...  0.757745  0.107177  0.721660   \n",
       "46006  0.656055  0.717538  0.695643  ...  0.571234  0.285999  0.706444   \n",
       "46007  0.690400  0.662287  0.543637  ...  0.820098  0.137484  0.769343   \n",
       "46008  0.690495  0.678824  0.570753  ...  0.798789  0.180341  0.777929   \n",
       "\n",
       "            x24  x25       x26       x27       x28       x29     error  \n",
       "0      0.454220  0.0  0.000000  0.244190  0.302358  0.322059  5.236656  \n",
       "1      0.267519  0.0  0.140804  0.198607  0.243114  0.317519  5.431109  \n",
       "2      0.272677  0.0  0.000000  0.367231  0.310925  0.305324  6.148790  \n",
       "3      0.562130  0.0  0.000000  0.487425  0.175516  0.529104  4.761903  \n",
       "4      0.547436  0.0  0.000000  0.485895  0.159511  0.516632  4.721280  \n",
       "...         ...  ...       ...       ...       ...       ...       ...  \n",
       "46004  0.576287  0.0  0.000000  0.342431  0.292779  0.382569  3.738620  \n",
       "46005  0.712792  0.0  0.000000  0.537675  0.032628  0.697988  3.176559  \n",
       "46006  0.751561  0.0  0.000000  0.480430  0.144457  0.659397  3.020452  \n",
       "46007  0.734681  0.0  0.000000  0.578817  0.083559  0.724466  3.245474  \n",
       "46008  0.751657  0.0  0.000000  0.582078  0.113273  0.723377  3.131653  \n",
       "\n",
       "[46009 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(x).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "columns = []\n",
    "\n",
    "for i in range(len(z[0])):\n",
    "    columns.append(\"x{}\".format(i))\n",
    "\n",
    "df_z = pd.DataFrame(z, columns=columns)\n",
    "\n",
    "# Normalize the data with MinMaxScaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "z_scaled = min_max_scaler.fit_transform(df_z.values)\n",
    "\n",
    "# Reassign to df_z\n",
    "df_z = pd.DataFrame(z_scaled, columns=columns)\n",
    "\n",
    "# Fetch the errors per data\n",
    "predictions = model(x)\n",
    "targets = x\n",
    "\n",
    "x_loss = nn.MSELoss(reduction='none')(predictions, targets).sum(axis=1).detach().cpu().numpy().astype(np.float32)\n",
    "df_z['error'] = x_loss\n",
    "\n",
    "df_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a0025",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Given the new dataset containing latent vectors and reconstruction error, we'll then perform clustering to form natural groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231dc4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [ -1   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16\n",
      "  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 192]\n",
      "Count for Cluster -1: 6537\n",
      "Count for Cluster 0: 7\n",
      "Count for Cluster 1: 9\n",
      "Count for Cluster 2: 5\n",
      "Count for Cluster 3: 8\n",
      "Count for Cluster 4: 5\n",
      "Count for Cluster 5: 226\n",
      "Count for Cluster 6: 33402\n",
      "Count for Cluster 7: 402\n",
      "Count for Cluster 8: 115\n",
      "Count for Cluster 9: 1199\n",
      "Count for Cluster 10: 291\n",
      "Count for Cluster 11: 99\n",
      "Count for Cluster 12: 6\n",
      "Count for Cluster 13: 98\n",
      "Count for Cluster 14: 32\n",
      "Count for Cluster 15: 111\n",
      "Count for Cluster 16: 16\n",
      "Count for Cluster 17: 117\n",
      "Count for Cluster 18: 12\n",
      "Count for Cluster 19: 369\n",
      "Count for Cluster 20: 391\n",
      "Count for Cluster 21: 10\n",
      "Count for Cluster 22: 20\n",
      "Count for Cluster 23: 18\n",
      "Count for Cluster 24: 9\n",
      "Count for Cluster 25: 15\n",
      "Count for Cluster 26: 9\n",
      "Count for Cluster 27: 100\n",
      "Count for Cluster 28: 119\n",
      "Count for Cluster 29: 73\n",
      "Count for Cluster 30: 12\n",
      "Count for Cluster 31: 7\n",
      "Count for Cluster 32: 41\n",
      "Count for Cluster 33: 37\n",
      "Count for Cluster 34: 5\n",
      "Count for Cluster 35: 6\n",
      "Count for Cluster 36: 19\n",
      "Count for Cluster 37: 54\n",
      "Count for Cluster 38: 4\n",
      "Count for Cluster 39: 6\n",
      "Count for Cluster 40: 6\n",
      "Count for Cluster 41: 11\n",
      "Count for Cluster 42: 18\n",
      "Count for Cluster 43: 40\n",
      "Count for Cluster 44: 22\n",
      "Count for Cluster 45: 7\n",
      "Count for Cluster 46: 68\n",
      "Count for Cluster 47: 37\n",
      "Count for Cluster 48: 23\n",
      "Count for Cluster 49: 16\n",
      "Count for Cluster 50: 34\n",
      "Count for Cluster 51: 7\n",
      "Count for Cluster 52: 7\n",
      "Count for Cluster 53: 12\n",
      "Count for Cluster 54: 18\n",
      "Count for Cluster 55: 18\n",
      "Count for Cluster 56: 15\n",
      "Count for Cluster 57: 8\n",
      "Count for Cluster 58: 17\n",
      "Count for Cluster 59: 34\n",
      "Count for Cluster 60: 7\n",
      "Count for Cluster 61: 19\n",
      "Count for Cluster 62: 15\n",
      "Count for Cluster 63: 7\n",
      "Count for Cluster 64: 7\n",
      "Count for Cluster 65: 82\n",
      "Count for Cluster 66: 5\n",
      "Count for Cluster 67: 10\n",
      "Count for Cluster 68: 5\n",
      "Count for Cluster 69: 70\n",
      "Count for Cluster 70: 5\n",
      "Count for Cluster 71: 6\n",
      "Count for Cluster 72: 9\n",
      "Count for Cluster 73: 5\n",
      "Count for Cluster 74: 7\n",
      "Count for Cluster 75: 8\n",
      "Count for Cluster 76: 11\n",
      "Count for Cluster 77: 13\n",
      "Count for Cluster 78: 29\n",
      "Count for Cluster 79: 34\n",
      "Count for Cluster 80: 38\n",
      "Count for Cluster 81: 10\n",
      "Count for Cluster 82: 7\n",
      "Count for Cluster 83: 6\n",
      "Count for Cluster 84: 8\n",
      "Count for Cluster 85: 5\n",
      "Count for Cluster 86: 11\n",
      "Count for Cluster 87: 10\n",
      "Count for Cluster 88: 9\n",
      "Count for Cluster 89: 8\n",
      "Count for Cluster 90: 25\n",
      "Count for Cluster 91: 6\n",
      "Count for Cluster 92: 7\n",
      "Count for Cluster 93: 14\n",
      "Count for Cluster 94: 6\n",
      "Count for Cluster 95: 15\n",
      "Count for Cluster 96: 11\n",
      "Count for Cluster 97: 20\n",
      "Count for Cluster 98: 8\n",
      "Count for Cluster 99: 9\n",
      "Count for Cluster 100: 6\n",
      "Count for Cluster 101: 5\n",
      "Count for Cluster 102: 5\n",
      "Count for Cluster 103: 11\n",
      "Count for Cluster 104: 5\n",
      "Count for Cluster 105: 8\n",
      "Count for Cluster 106: 6\n",
      "Count for Cluster 107: 11\n",
      "Count for Cluster 108: 9\n",
      "Count for Cluster 109: 12\n",
      "Count for Cluster 110: 5\n",
      "Count for Cluster 111: 11\n",
      "Count for Cluster 112: 13\n",
      "Count for Cluster 113: 5\n",
      "Count for Cluster 114: 5\n",
      "Count for Cluster 115: 6\n",
      "Count for Cluster 116: 10\n",
      "Count for Cluster 117: 12\n",
      "Count for Cluster 118: 7\n",
      "Count for Cluster 119: 5\n",
      "Count for Cluster 120: 5\n",
      "Count for Cluster 121: 6\n",
      "Count for Cluster 122: 5\n",
      "Count for Cluster 123: 10\n",
      "Count for Cluster 124: 9\n",
      "Count for Cluster 125: 6\n",
      "Count for Cluster 126: 7\n",
      "Count for Cluster 127: 7\n",
      "Count for Cluster 128: 11\n",
      "Count for Cluster 129: 5\n",
      "Count for Cluster 130: 6\n",
      "Count for Cluster 131: 7\n",
      "Count for Cluster 132: 5\n",
      "Count for Cluster 133: 5\n",
      "Count for Cluster 134: 5\n",
      "Count for Cluster 135: 5\n",
      "Count for Cluster 136: 9\n",
      "Count for Cluster 137: 6\n",
      "Count for Cluster 138: 5\n",
      "Count for Cluster 139: 7\n",
      "Count for Cluster 140: 5\n",
      "Count for Cluster 141: 16\n",
      "Count for Cluster 142: 13\n",
      "Count for Cluster 143: 5\n",
      "Count for Cluster 144: 7\n",
      "Count for Cluster 145: 5\n",
      "Count for Cluster 146: 5\n",
      "Count for Cluster 147: 4\n",
      "Count for Cluster 148: 12\n",
      "Count for Cluster 149: 7\n",
      "Count for Cluster 150: 5\n",
      "Count for Cluster 151: 6\n",
      "Count for Cluster 152: 3\n",
      "Count for Cluster 153: 5\n",
      "Count for Cluster 154: 6\n",
      "Count for Cluster 155: 5\n",
      "Count for Cluster 156: 5\n",
      "Count for Cluster 157: 5\n",
      "Count for Cluster 158: 7\n",
      "Count for Cluster 159: 7\n",
      "Count for Cluster 160: 5\n",
      "Count for Cluster 161: 4\n",
      "Count for Cluster 162: 6\n",
      "Count for Cluster 163: 10\n",
      "Count for Cluster 164: 6\n",
      "Count for Cluster 165: 7\n",
      "Count for Cluster 166: 6\n",
      "Count for Cluster 167: 6\n",
      "Count for Cluster 168: 6\n",
      "Count for Cluster 169: 5\n",
      "Count for Cluster 170: 5\n",
      "Count for Cluster 171: 5\n",
      "Count for Cluster 172: 5\n",
      "Count for Cluster 173: 5\n",
      "Count for Cluster 174: 4\n",
      "Count for Cluster 175: 5\n",
      "Count for Cluster 176: 7\n",
      "Count for Cluster 177: 8\n",
      "Count for Cluster 178: 13\n",
      "Count for Cluster 179: 9\n",
      "Count for Cluster 180: 11\n",
      "Count for Cluster 181: 8\n",
      "Count for Cluster 182: 8\n",
      "Count for Cluster 183: 359\n",
      "Count for Cluster 184: 6\n",
      "Count for Cluster 185: 5\n",
      "Count for Cluster 186: 10\n",
      "Count for Cluster 187: 5\n",
      "Count for Cluster 188: 5\n",
      "Count for Cluster 189: 5\n",
      "Count for Cluster 190: 5\n",
      "Count for Cluster 191: 3\n",
      "Count for Cluster 192: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>error</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793240</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363471</td>\n",
       "      <td>0.541753</td>\n",
       "      <td>0.406474</td>\n",
       "      <td>0.277373</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483487</td>\n",
       "      <td>0.454220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244190</td>\n",
       "      <td>0.302358</td>\n",
       "      <td>0.322059</td>\n",
       "      <td>5.236656</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788108</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.366993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>0.087326</td>\n",
       "      <td>0.286169</td>\n",
       "      <td>0.316868</td>\n",
       "      <td>0.397639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648108</td>\n",
       "      <td>0.267519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140804</td>\n",
       "      <td>0.198607</td>\n",
       "      <td>0.243114</td>\n",
       "      <td>0.317519</td>\n",
       "      <td>5.431109</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.455536</td>\n",
       "      <td>0.148629</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>0.189248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.228299</td>\n",
       "      <td>0.402206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.147582</td>\n",
       "      <td>0.272677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367231</td>\n",
       "      <td>0.310925</td>\n",
       "      <td>0.305324</td>\n",
       "      <td>6.148790</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.241962</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>0.110588</td>\n",
       "      <td>0.526672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318677</td>\n",
       "      <td>0.788280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536704</td>\n",
       "      <td>0.358023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034238</td>\n",
       "      <td>0.490966</td>\n",
       "      <td>0.562130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487425</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>0.529104</td>\n",
       "      <td>4.761903</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251684</td>\n",
       "      <td>0.698637</td>\n",
       "      <td>0.134919</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325630</td>\n",
       "      <td>0.769554</td>\n",
       "      <td>0.982958</td>\n",
       "      <td>0.532264</td>\n",
       "      <td>0.341555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039653</td>\n",
       "      <td>0.476847</td>\n",
       "      <td>0.547436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485895</td>\n",
       "      <td>0.159511</td>\n",
       "      <td>0.516632</td>\n",
       "      <td>4.721280</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46004</th>\n",
       "      <td>0.650656</td>\n",
       "      <td>0.798774</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526098</td>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.646661</td>\n",
       "      <td>0.584388</td>\n",
       "      <td>0.662517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387673</td>\n",
       "      <td>0.514687</td>\n",
       "      <td>0.576287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342431</td>\n",
       "      <td>0.292779</td>\n",
       "      <td>0.382569</td>\n",
       "      <td>3.738620</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>0.592062</td>\n",
       "      <td>0.566196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.426163</td>\n",
       "      <td>0.583065</td>\n",
       "      <td>0.668464</td>\n",
       "      <td>0.650636</td>\n",
       "      <td>0.541520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107177</td>\n",
       "      <td>0.721660</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537675</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>0.697988</td>\n",
       "      <td>3.176559</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46006</th>\n",
       "      <td>0.689835</td>\n",
       "      <td>0.706366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476489</td>\n",
       "      <td>0.594329</td>\n",
       "      <td>0.656055</td>\n",
       "      <td>0.717538</td>\n",
       "      <td>0.695643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285999</td>\n",
       "      <td>0.706444</td>\n",
       "      <td>0.751561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480430</td>\n",
       "      <td>0.144457</td>\n",
       "      <td>0.659397</td>\n",
       "      <td>3.020452</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46007</th>\n",
       "      <td>0.592263</td>\n",
       "      <td>0.538188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467956</td>\n",
       "      <td>0.565733</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.662287</td>\n",
       "      <td>0.543637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137484</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.734681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578817</td>\n",
       "      <td>0.083559</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>3.245474</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46008</th>\n",
       "      <td>0.611027</td>\n",
       "      <td>0.554694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487942</td>\n",
       "      <td>0.566152</td>\n",
       "      <td>0.690495</td>\n",
       "      <td>0.678824</td>\n",
       "      <td>0.570753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180341</td>\n",
       "      <td>0.777929</td>\n",
       "      <td>0.751657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582078</td>\n",
       "      <td>0.113273</td>\n",
       "      <td>0.723377</td>\n",
       "      <td>3.131653</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46009 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3   x4        x5        x6  \\\n",
       "0      0.793240  0.826811  0.000000  0.634476  0.0  0.363471  0.541753   \n",
       "1      0.788108  0.362938  0.161218  0.366993  0.0  0.389249  0.087326   \n",
       "2      0.455536  0.148629  0.055008  0.189248  0.0  0.283654  0.228299   \n",
       "3      0.241962  0.711267  0.110588  0.526672  0.0  0.318677  0.788280   \n",
       "4      0.251684  0.698637  0.134919  0.529032  0.0  0.325630  0.769554   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "46004  0.650656  0.798774  0.062688  0.319400  0.0  0.526098  0.499348   \n",
       "46005  0.592062  0.566196  0.000000  0.174644  0.0  0.426163  0.583065   \n",
       "46006  0.689835  0.706366  0.000000  0.388670  0.0  0.476489  0.594329   \n",
       "46007  0.592263  0.538188  0.000000  0.193895  0.0  0.467956  0.565733   \n",
       "46008  0.611027  0.554694  0.000000  0.240257  0.0  0.487942  0.566152   \n",
       "\n",
       "             x7        x8        x9  ...       x22       x23       x24  x25  \\\n",
       "0      0.406474  0.277373  0.465755  ...  0.000000  0.483487  0.454220  0.0   \n",
       "1      0.286169  0.316868  0.397639  ...  0.000000  0.648108  0.267519  0.0   \n",
       "2      0.402206  0.000000  0.109701  ...  0.014701  0.147582  0.272677  0.0   \n",
       "3      1.000000  0.536704  0.358023  ...  0.034238  0.490966  0.562130  0.0   \n",
       "4      0.982958  0.532264  0.341555  ...  0.039653  0.476847  0.547436  0.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...  ...   \n",
       "46004  0.646661  0.584388  0.662517  ...  0.387673  0.514687  0.576287  0.0   \n",
       "46005  0.668464  0.650636  0.541520  ...  0.107177  0.721660  0.712792  0.0   \n",
       "46006  0.656055  0.717538  0.695643  ...  0.285999  0.706444  0.751561  0.0   \n",
       "46007  0.690400  0.662287  0.543637  ...  0.137484  0.769343  0.734681  0.0   \n",
       "46008  0.690495  0.678824  0.570753  ...  0.180341  0.777929  0.751657  0.0   \n",
       "\n",
       "            x26       x27       x28       x29     error  cluster_label  \n",
       "0      0.000000  0.244190  0.302358  0.322059  5.236656             -1  \n",
       "1      0.140804  0.198607  0.243114  0.317519  5.431109             -1  \n",
       "2      0.000000  0.367231  0.310925  0.305324  6.148790             -1  \n",
       "3      0.000000  0.487425  0.175516  0.529104  4.761903             -1  \n",
       "4      0.000000  0.485895  0.159511  0.516632  4.721280             -1  \n",
       "...         ...       ...       ...       ...       ...            ...  \n",
       "46004  0.000000  0.342431  0.292779  0.382569  3.738620             -1  \n",
       "46005  0.000000  0.537675  0.032628  0.697988  3.176559              6  \n",
       "46006  0.000000  0.480430  0.144457  0.659397  3.020452             19  \n",
       "46007  0.000000  0.578817  0.083559  0.724466  3.245474              6  \n",
       "46008  0.000000  0.582078  0.113273  0.723377  3.131653              6  \n",
       "\n",
       "[46009 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(df_z.values)\n",
    "\n",
    "unique_labels = np.unique(clustering.labels_)\n",
    "\n",
    "print(\"Cluster labels: {}\".format(unique_labels))\n",
    "\n",
    "df_z_with_cluster_labels = df_z.copy()\n",
    "df_z_with_cluster_labels['cluster_label'] = clustering.labels_\n",
    "\n",
    "for cluster_label in unique_labels:\n",
    "    count = len(df_z_with_cluster_labels[df_z_with_cluster_labels['cluster_label'] == cluster_label])\n",
    "    print(\"Count for Cluster {}: {}\".format(cluster_label, count))\n",
    "    \n",
    "df_z_with_cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a25a26a",
   "metadata": {},
   "source": [
    "## Visualizing Clusters\n",
    "\n",
    "Use TSNE to reduce to 3 dimensions for visualization and plotly 3d scatterplot for visualization.\n",
    "\n",
    "**Documentation:**\n",
    "* **TSNE:**: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "* **Plotly 3D Scatterplot:**: https://plotly.com/python/3d-scatter-plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19baac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a TSNE model with 3 dimensions\n",
    "# z_embedded = TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df_z.values)\n",
    "\n",
    "# # Create a new data frame for result of tsne and attach cluster label\n",
    "# df_z_embedded = pd.DataFrame(z_embedded, columns=['x', 'y', 'z'])\n",
    "# df_z_embedded['cluster_label'] = df_z_with_cluster_labels['cluster_label']\n",
    "\n",
    "# # Visualize with 3D scatterplot\n",
    "# fig = px.scatter_3d(df_z_embedded, x='x', y='y', z='z', color='cluster_label')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e648b20",
   "metadata": {},
   "source": [
    "## Training for Perceived Normal Data\n",
    "\n",
    "We now train a new autoencoder model for data points whose cluster_label is not equal to -1. This will serve as our prediction model for auto-thresholding later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febcadad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39472 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x0   x1        x2   x3        x4        x5        x6   x7   x8   x9  \\\n",
       "5      0.0  1.0  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0  0.0   \n",
       "6      0.0  1.0  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0  0.0   \n",
       "7      0.0  1.0  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0  0.0   \n",
       "9      0.0  1.0  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0  0.0   \n",
       "10     0.0  1.0  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0  0.0   \n",
       "...    ...  ...       ...  ...       ...       ...       ...  ...  ...  ...   \n",
       "46002  0.0  0.0  0.000000  0.0  0.000044  0.001747  0.000000  0.0  0.0  0.0   \n",
       "46005  0.0  0.0  0.000000  0.0  0.000036  0.000778  0.000000  0.0  0.0  0.0   \n",
       "46006  0.0  0.0  0.000000  0.0  0.000032  0.001299  0.000000  0.0  0.0  0.0   \n",
       "46007  0.0  0.0  0.000000  0.0  0.000054  0.000553  0.000000  0.0  0.0  0.0   \n",
       "46008  0.0  0.0  0.000000  0.0  0.000057  0.000268  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "       ...       x30       x31  x32  x33   x34   x35  x36  x37  x38  x39  \n",
       "5      ...  0.003922  0.027451  1.0  0.0  1.00  0.57  0.0  0.0  0.0  0.0  \n",
       "6      ...  0.003922  0.035294  1.0  0.0  1.00  0.56  0.0  0.0  0.0  0.0  \n",
       "7      ...  0.003922  0.043137  1.0  0.0  1.00  0.55  0.0  0.0  0.0  0.0  \n",
       "9      ...  0.003922  0.050980  1.0  0.0  1.00  0.54  0.0  0.0  0.0  0.0  \n",
       "10     ...  0.003922  0.066667  1.0  0.0  1.00  0.53  0.0  0.0  0.0  0.0  \n",
       "...    ...       ...       ...  ...  ...   ...   ...  ...  ...  ...  ...  \n",
       "46002  ...  0.760784  1.000000  1.0  0.0  0.01  0.03  0.0  0.0  0.0  0.0  \n",
       "46005  ...  0.784314  1.000000  1.0  0.0  0.00  0.02  0.0  0.0  0.0  0.0  \n",
       "46006  ...  0.482353  1.000000  1.0  0.0  0.01  0.06  0.0  0.0  0.0  0.0  \n",
       "46007  ...  1.000000  1.000000  1.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  \n",
       "46008  ...  1.000000  1.000000  1.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[39472 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal = df_train_x.copy()\n",
    "df_normal = df_normal[df_z_with_cluster_labels['cluster_label'] != -1]\n",
    "\n",
    "df_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46e38ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:12<00:00, 327.14it/s, loss=0.0715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 329.97it/s, loss=0.0639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:10<00:00, 393.97it/s, loss=0.0566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:09<00:00, 398.26it/s, loss=0.0498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 347.92it/s, loss=0.0436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 354.22it/s, loss=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 353.34it/s, loss=0.0329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 351.90it/s, loss=0.0284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 345.69it/s, loss=0.0245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 352.11it/s, loss=0.021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 349.25it/s, loss=0.0181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 354.40it/s, loss=0.0156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 356.45it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 356.93it/s, loss=0.0117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 343.25it/s, loss=0.0103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 345.57it/s, loss=0.00906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 345.27it/s, loss=0.00808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 342.48it/s, loss=0.0073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:12<00:00, 312.01it/s, loss=0.00667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3948/3948 [00:11<00:00, 334.30it/s, loss=0.00616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Represent the training data as x\n",
    "x = torch.tensor(df_normal.values).float().to(device)\n",
    "\n",
    "# Load the dataset\n",
    "train_ds = AutoencoderDataset(x=x)\n",
    "\n",
    "# Create a DataLoader instance\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# The training process\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    loop = tqdm(train_loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Feed forward\n",
    "        predictions = model(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408253f",
   "metadata": {},
   "source": [
    "## Threshold Computation\n",
    "\n",
    "Using reconstruction errors, compute for the reconstruction threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49279f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Width: 0.010862015774920339\n",
      "Num Bins: 724\n",
      "Max Loss: 7.961540222167969\n",
      "Min Loss: 0.0947180986404419\n",
      "Min Bin: 0.0947180986404419\n",
      "Max Bin: 8.056258201599121\n",
      "Optimal Threshold: 1.3868188943652164\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Utility Functions\n",
    "\"\"\"\n",
    "# Head tail break function\n",
    "def htb(data):\n",
    "    outp = []\n",
    "    \n",
    "    def htb_inner(data):\n",
    "        data_length = float(len(data))\n",
    "        data_mean = sum(data) / data_length\n",
    "        \n",
    "        head = [_ for _ in data if _ > data_mean]\n",
    "        outp.append(data_mean)\n",
    "        \n",
    "        while len(head) > 1 and len(head) / data_length < 0.40:\n",
    "            return htb_inner(head)\n",
    "        \n",
    "    htb_inner(data)\n",
    "    \n",
    "    return outp\n",
    "\n",
    "# Determine a breakpoint\n",
    "def fetch_threshold(bins, counts, break_point):\n",
    "    index = 0\n",
    "    latest_min = 999999\n",
    "    threshold = -1\n",
    "    \n",
    "    for i in range(len(counts)):\n",
    "        diff = abs(counts[i] - break_point)\n",
    "        \n",
    "        if diff <= latest_min:\n",
    "            latest_min = diff\n",
    "            index = i\n",
    "            threshold = ((bins[i + 1] - bins[i]) / 2) + bins[i]\n",
    "            \n",
    "    return threshold\n",
    "\n",
    "predictions = model(x)\n",
    "targets = x\n",
    "\n",
    "x_loss = nn.MSELoss(reduction='none')(predictions, targets).sum(axis=1).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "max_loss = np.max(x_loss)\n",
    "min_loss = np.min(x_loss)\n",
    "\n",
    "# Compute the optimal bin width using Freedman Diaconis rule\n",
    "bin_width = 2 * (iqr(x_loss) / (len(x_loss) ** (1./3)))\n",
    "num_bins = int((max_loss - min_loss) / bin_width)\n",
    "\n",
    "# Create the histogram\n",
    "min_bin = np.min(x_loss)\n",
    "max_bin = np.max(x_loss) + min_bin\n",
    "\n",
    "step = (max_bin - min_bin) / num_bins\n",
    "\n",
    "bins = np.arange(min_bin, max_bin, step)\n",
    "\n",
    "hist, bins = np.histogram(x_loss, bins=bins)\n",
    "\n",
    "pyplot.hist(x_loss, bins, alpha=0.5)\n",
    "pyplot.show()\n",
    "\n",
    "print(\"Bin Width: {}\".format(bin_width))\n",
    "print(\"Num Bins: {}\".format(num_bins))\n",
    "print(\"Max Loss: {}\".format(max_loss))\n",
    "print(\"Min Loss: {}\".format(min_loss))\n",
    "print(\"Min Bin: {}\".format(min_bin))\n",
    "print(\"Max Bin: {}\".format(max_bin))\n",
    "\n",
    "\n",
    "\n",
    "# Determine breaks\n",
    "breaks = htb(hist)\n",
    "\n",
    "possible_thresholds = []\n",
    "\n",
    "for b in breaks:\n",
    "    t = fetch_threshold(bins, hist, b)\n",
    "    possible_thresholds.append(t)\n",
    "\n",
    "optimal_threshold = max(possible_thresholds)\n",
    "\n",
    "print(\"Optimal Threshold: {}\".format(optimal_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac907864",
   "metadata": {},
   "source": [
    "## Compute for Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94bddfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484582</td>\n",
       "      <td>0.255578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0        x1        x2        x3        x4        x5   x6   x7   x8  \\\n",
       "0     0.0  0.000000  0.335534  0.593385  0.000000  0.000000  0.0  0.0  0.0   \n",
       "1     0.0  0.000000  0.335534  0.593385  0.000000  0.000000  0.0  0.0  0.0   \n",
       "2     0.0  0.000000  0.335534  0.593385  0.000000  0.000000  0.0  0.0  0.0   \n",
       "3     0.0  0.000000  0.335534  0.593385  0.000000  0.000000  0.0  0.0  0.0   \n",
       "4     0.0  0.000000  0.335534  0.593385  0.000000  0.000000  0.0  0.0  0.0   \n",
       "...   ...       ...       ...       ...       ...       ...  ...  ...  ...   \n",
       "2095  0.0  0.484582  0.255578  0.000000  0.000007  0.000025  0.0  0.0  0.0   \n",
       "2096  0.0  1.000000  0.514821  0.000000  0.000005  0.000000  0.0  0.0  0.0   \n",
       "2097  0.0  1.000000  0.514821  0.000000  0.000005  0.000000  0.0  0.0  0.0   \n",
       "2098  0.0  1.000000  0.514821  0.000000  0.000005  0.000000  0.0  0.0  0.0   \n",
       "2099  0.0  1.000000  0.514821  0.000000  0.000005  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "       x9  ...       x31   x32  x33  x34  x35  x36  x37  x38  x39  y  \n",
       "0     0.0  ...  0.003922  0.01  1.0  1.0  0.0  1.0  1.0  0.0  0.0 -1  \n",
       "1     0.0  ...  0.003922  0.01  1.0  1.0  0.0  1.0  1.0  0.0  0.0 -1  \n",
       "2     0.0  ...  0.003922  0.01  1.0  1.0  0.0  1.0  1.0  0.0  0.0 -1  \n",
       "3     0.0  ...  0.003922  0.01  1.0  1.0  0.0  1.0  1.0  0.0  0.0 -1  \n",
       "4     0.0  ...  0.003922  0.01  1.0  1.0  0.0  1.0  1.0  0.0  0.0 -1  \n",
       "...   ...  ...       ...   ...  ...  ...  ...  ...  ...  ...  ... ..  \n",
       "2095  0.0  ...  1.000000  1.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1  \n",
       "2096  0.0  ...  0.215686  1.00  0.0  1.0  0.0  0.0  0.0  0.0  0.0 -1  \n",
       "2097  0.0  ...  0.219608  1.00  0.0  1.0  0.0  0.0  0.0  0.0  0.0 -1  \n",
       "2098  0.0  ...  0.262745  1.00  0.0  1.0  0.0  0.0  0.0  0.0  0.0 -1  \n",
       "2099  0.0  ...  0.298039  1.00  0.0  1.0  0.0  0.0  0.0  0.0  0.0 -1  \n",
       "\n",
       "[2100 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to tensor\n",
    "x = torch.tensor(df_test_x.values).float().to(device)\n",
    "\n",
    "predictions = model(x)\n",
    "targets = x\n",
    "\n",
    "# Get reconstruction error\n",
    "x_loss = nn.MSELoss(reduction='none')(predictions, targets).sum(axis=1).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "# If reconstruction error is >= than the optimal threshold, we consider it an anomaly\n",
    "bool_arr = x_loss >= optimal_threshold\n",
    "\n",
    "# Convert anomaly labels to -1 if True and 1 if False\n",
    "anomaly_predictions = np.array([-1 if elem else 1 for elem in bool_arr])\n",
    "\n",
    "# Build dataframe for test data and attach predictions\n",
    "df_test_x_with_labels = df_test_x.copy()\n",
    "df_test_x_with_labels['y'] = anomaly_predictions\n",
    "\n",
    "df_test_x_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c57564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a TSNE model with 3 dimensions\n",
    "# z_embedded = TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df_test_x_with_labels.drop(columns=['y'], axis=1).values)\n",
    "\n",
    "# # Create a new data frame for result of tsne and attach cluster label\n",
    "# df_z_embedded = pd.DataFrame(z_embedded, columns=['x', 'y', 'z'])\n",
    "# df_z_embedded['y'] = anomaly_predictions\n",
    "\n",
    "# # Visualize with 3D scatterplot\n",
    "# fig = px.scatter_3d(df_z_embedded, x='x', y='y', z='z', color='y')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0bac8",
   "metadata": {},
   "source": [
    "## Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f979ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 0\n",
      "True Negative: 263\n",
      "False Positive: 1837\n",
      "False Negative: 0\n",
      "F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "ground_truth = np.array([1 if elem == 1 else -1 for elem in df_test_y.values])\n",
    "\n",
    "y_truth = np.array([0 if elem == -1 else 1 for elem in ground_truth])\n",
    "y_predictions = np.array([0 if elem == -1 else 1 for elem in anomaly_predictions])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(ground_truth, anomaly_predictions).ravel()\n",
    "tn, fp, fn, tp = confusion_matrix(y_truth, y_predictions).ravel()\n",
    "\n",
    "f1 = tp / (tp + 0.5* (fp + fn))\n",
    "\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"F1: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fa6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(y, bool_a, errors, threshold, max_err):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if bool_a[i]:\n",
    "            prob_anomaly = 0.5 + (1 - (threshold / x_loss[i]))\n",
    "            \n",
    "            if prob_anomaly > 1:\n",
    "                prob_anomaly = 0.99\n",
    "                \n",
    "            prob_normal = 1 - prob_anomaly\n",
    "                \n",
    "            results.append([prob_normal, prob_anomaly])\n",
    "        else:\n",
    "            prob_normal = 0.5 + (1 - (x_loss[i] / threshold))\n",
    "            \n",
    "            if prob_normal > 1:\n",
    "                prob_normal = 0.99\n",
    "            \n",
    "            prob_anomaly = 1 - prob_normal\n",
    "            \n",
    "            results.append([prob_normal, prob_anomaly])\n",
    "    \n",
    "    return results\n",
    "\n",
    "y_probs = predict_proba(y_truth, bool_arr, x_loss, optimal_threshold, np.max(x_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95bbbd",
   "metadata": {},
   "source": [
    "## ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "616f05c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(mapper, y_probs))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(probabilities)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC AUC: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m auc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_truth, probabilities)\n",
      "File \u001b[0;32m~/workspace/notebooks/env/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:567\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    565\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    566\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    576\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    577\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    581\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/notebooks/env/lib/python3.9/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/workspace/notebooks/env/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:337\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    342\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def mapper(arr):\n",
    "    return arr[0]\n",
    "\n",
    "probabilities = list(map(mapper, y_probs))\n",
    "# print(probabilities)\n",
    "\n",
    "auc = roc_auc_score(y_truth, probabilities)\n",
    "print('ROC AUC: %f' % auc, '\\n')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_truth, probabilities)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f)\" % auc,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
