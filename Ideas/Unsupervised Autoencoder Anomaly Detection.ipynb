{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6df3849",
   "metadata": {},
   "source": [
    "## Unsupervised Autoencoder Anomaly Detection\n",
    "\n",
    "1. Train an autoencoder to capture latent representation of entire dataset\n",
    "2. Extract the latent representation of the entire dataset\n",
    "3. Append the reconstruction error as part of the feature vector for the latent representation dataset\n",
    "4. Perform clustering against the new dataset to determine natural groupings\n",
    "5. Train another autoencoder against datapoints within groupings treated as normal\n",
    "6. Apply autothresholding with head tail break\n",
    "7. Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c0a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append('..')\n",
    "\n",
    "from lib.autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485132ff",
   "metadata": {},
   "source": [
    "## Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f3f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of csv training file\n",
    "ds_train_file = \"../Datasets/thyroid_train.csv\"\n",
    "# Location of csv test file\n",
    "ds_test_file = \"../Datasets/thyroid_test.csv\" \n",
    "\n",
    "# Dataframe instance for training data\n",
    "df_train = pd.read_csv(ds_train_file)\n",
    "# Dataframe instance for test data\n",
    "df_test = pd.read_csv(ds_test_file)\n",
    "\n",
    "# Expected number of features\n",
    "n_features = 21\n",
    "\n",
    "# Extracted dataframe for all training values without labels\n",
    "df_train_x = df_train.drop(['y'], axis=1)\n",
    "# Extracted dataframe for all labels of training data\n",
    "df_train_y = df_train['y']\n",
    "\n",
    "# Extracted dataframe for all test values without labels\n",
    "df_test_x = df_test.drop(['y'], axis=1)\n",
    "# Extracted dataframe for all test labels of testing data\n",
    "df_test_y = df_test['y']\n",
    "\n",
    "# Autoencoder parameter for layers. First element is the size of the input vector. Succeeding values are hidden layers for the encoder\n",
    "layers = [21, 10]\n",
    "\n",
    "# Autoencoder parameter for hidden activation\n",
    "h_activation = 'relu'\n",
    "\n",
    "# Autoencoder parameter for output activation\n",
    "o_activation = 'sigmoid'\n",
    "\n",
    "# Autoencoder parameter for learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Torch parameter for device\n",
    "device = 'cpu'\n",
    "\n",
    "# Training parameter for number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Training parameter for batch size\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e575bf6",
   "metadata": {},
   "source": [
    "## Train Autoencoder Model\n",
    "\n",
    "The first autoencoder will attempt to get the latent representation of the data regardless of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(layers=layers, h_activation=h_activation, o_activation=o_activation, device=device)\n",
    "\n",
    "# Represent the training data as x\n",
    "x = torch.tensor(df_train_x.values).float().to(device)\n",
    "\n",
    "train_ds = AutoencoderDataset(x=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
