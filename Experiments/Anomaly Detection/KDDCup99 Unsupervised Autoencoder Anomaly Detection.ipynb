{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6df3849",
   "metadata": {},
   "source": [
    "## Unsupervised Autoencoder Anomaly Detection\n",
    "\n",
    "1. Train an autoencoder to capture latent representation of entire dataset\n",
    "2. Extract the latent representation of the entire dataset\n",
    "3. Append the reconstruction error as part of the feature vector for the latent representation dataset\n",
    "4. Perform clustering against the new dataset to determine natural groupings\n",
    "5. Train another autoencoder against datapoints within groupings treated as normal\n",
    "6. Apply autothresholding with head tail break\n",
    "7. Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c0a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.stats import iqr\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('../../')\n",
    "\n",
    "from lib.autoencoder import Autoencoder\n",
    "from lib.autoencoder_dataset import AutoencoderDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485132ff",
   "metadata": {},
   "source": [
    "## Experimental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f3f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label column\n",
    "label_column = 'y'\n",
    "\n",
    "ds_train_file = \"../../Datasets/train_1000_50_kddcup99.csv\"\n",
    "ds_test_file = \"../../Datasets/test_46913_146_kddcup99.csv\"\n",
    "\n",
    "# Dataframe instance for training data\n",
    "df_train = pd.read_csv(ds_train_file)\n",
    "# Dataframe instance for test data\n",
    "df_test = pd.read_csv(ds_test_file)\n",
    "\n",
    "# Expected number of features\n",
    "n_features = 40\n",
    "\n",
    "# Extracted dataframe for all training values without labels\n",
    "df_train_x = df_train.drop([label_column], axis=1)\n",
    "# Extracted dataframe for all labels of training data\n",
    "df_train_y = df_train[label_column]\n",
    "\n",
    "# Extracted dataframe for all test values without labels\n",
    "df_test_x = df_test.drop(['y'], axis=1)\n",
    "# Extracted dataframe for all test labels of testing data\n",
    "df_test_y = df_test['y']\n",
    "\n",
    "# Autoencoder parameter for layers. First element is the size of the input vector. Succeeding values are hidden layers for the encoder\n",
    "layers = [40, 30]\n",
    "\n",
    "# Autoencoder parameter for hidden activation\n",
    "h_activation = 'relu'\n",
    "\n",
    "# Autoencoder parameter for output activation\n",
    "o_activation = 'sigmoid'\n",
    "\n",
    "# Autoencoder parameter for learning rate\n",
    "learning_rate = 0.00001\n",
    "\n",
    "# Torch parameter for device\n",
    "device = 'cpu'\n",
    "\n",
    "# Training parameter for number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Training parameter for batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# DBSCAN parameter eps\n",
    "eps = 0.04\n",
    "\n",
    "# DBSCAN parameter minimum samples\n",
    "min_samples = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e575bf6",
   "metadata": {},
   "source": [
    "## Train Autoencoder Model\n",
    "\n",
    "The first autoencoder will attempt to get the latent representation of the data regardless of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c516380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 602.74it/s, loss=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:04<00:00, 501.90it/s, loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:04<00:00, 569.74it/s, loss=0.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 620.33it/s, loss=0.314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 646.77it/s, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 658.74it/s, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:04<00:00, 585.79it/s, loss=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:04<00:00, 540.88it/s, loss=0.222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:04<00:00, 554.17it/s, loss=0.217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 631.05it/s, loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 628.72it/s, loss=0.208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 633.96it/s, loss=0.203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 642.57it/s, loss=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 638.89it/s, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 609.33it/s, loss=0.191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:04<00:00, 582.29it/s, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 619.33it/s, loss=0.185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 623.99it/s, loss=0.182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 697.07it/s, loss=0.179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 734.64it/s, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 676.73it/s, loss=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 650.72it/s, loss=0.171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 671.87it/s, loss=0.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 685.49it/s, loss=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 662.35it/s, loss=0.164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 707.25it/s, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 632.98it/s, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 637.81it/s, loss=0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 659.92it/s, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 691.60it/s, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 699.38it/s, loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 654.10it/s, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 649.05it/s, loss=0.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 645.09it/s, loss=0.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 664.37it/s, loss=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 661.19it/s, loss=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 669.06it/s, loss=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 673.12it/s, loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 645.42it/s, loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 665.70it/s, loss=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 675.76it/s, loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 676.21it/s, loss=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 669.41it/s, loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 681.51it/s, loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 664.81it/s, loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 698.12it/s, loss=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 693.35it/s, loss=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 702.67it/s, loss=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 711.78it/s, loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2353/2353 [00:03<00:00, 698.69it/s, loss=0.101]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(layers=layers, h_activation=h_activation, o_activation=o_activation, device=device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Represent the training data as x\n",
    "x = torch.tensor(df_train_x.values).float().to(device)\n",
    "\n",
    "# Load the dataset\n",
    "train_ds = AutoencoderDataset(x=x)\n",
    "\n",
    "# Create a DataLoader instance\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# The training process\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    loop = tqdm(train_loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Feed forward\n",
    "        predictions = model(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac609821",
   "metadata": {},
   "source": [
    "## Compression\n",
    "\n",
    "Using the trained autoencoder, compress the data to latent space and create a new data frame containing latent vectors and reconstruction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a7a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.490075</td>\n",
       "      <td>0.586673</td>\n",
       "      <td>0.151645</td>\n",
       "      <td>0.417871</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.634610</td>\n",
       "      <td>0.108587</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.263761</td>\n",
       "      <td>0.654423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314657</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.654252</td>\n",
       "      <td>0.153930</td>\n",
       "      <td>0.975584</td>\n",
       "      <td>0.657599</td>\n",
       "      <td>0.305233</td>\n",
       "      <td>3.855455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501998</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.302396</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.402819</td>\n",
       "      <td>0.539508</td>\n",
       "      <td>0.594899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602166</td>\n",
       "      <td>0.423305</td>\n",
       "      <td>0.627015</td>\n",
       "      <td>0.470412</td>\n",
       "      <td>0.637579</td>\n",
       "      <td>0.205152</td>\n",
       "      <td>0.358128</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.527753</td>\n",
       "      <td>2.230361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.668628</td>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731785</td>\n",
       "      <td>0.581351</td>\n",
       "      <td>0.320759</td>\n",
       "      <td>0.923884</td>\n",
       "      <td>0.128919</td>\n",
       "      <td>0.481807</td>\n",
       "      <td>0.229775</td>\n",
       "      <td>0.136514</td>\n",
       "      <td>0.203936</td>\n",
       "      <td>2.073030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119585</td>\n",
       "      <td>0.606693</td>\n",
       "      <td>0.365430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555020</td>\n",
       "      <td>0.058068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524448</td>\n",
       "      <td>0.190185</td>\n",
       "      <td>0.221936</td>\n",
       "      <td>0.405749</td>\n",
       "      <td>0.141641</td>\n",
       "      <td>0.963556</td>\n",
       "      <td>0.915166</td>\n",
       "      <td>0.502258</td>\n",
       "      <td>0.305077</td>\n",
       "      <td>1.785131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113869</td>\n",
       "      <td>0.567921</td>\n",
       "      <td>0.367087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540726</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.206480</td>\n",
       "      <td>0.221795</td>\n",
       "      <td>0.418604</td>\n",
       "      <td>0.127562</td>\n",
       "      <td>0.955616</td>\n",
       "      <td>0.891303</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.308274</td>\n",
       "      <td>1.656335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47054</th>\n",
       "      <td>0.465896</td>\n",
       "      <td>0.259782</td>\n",
       "      <td>0.823485</td>\n",
       "      <td>0.612409</td>\n",
       "      <td>0.270203</td>\n",
       "      <td>0.267166</td>\n",
       "      <td>0.260125</td>\n",
       "      <td>0.593737</td>\n",
       "      <td>0.075529</td>\n",
       "      <td>0.461807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933103</td>\n",
       "      <td>0.877858</td>\n",
       "      <td>0.429925</td>\n",
       "      <td>0.684466</td>\n",
       "      <td>0.519460</td>\n",
       "      <td>0.723924</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.180541</td>\n",
       "      <td>0.501408</td>\n",
       "      <td>0.237799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47055</th>\n",
       "      <td>0.139747</td>\n",
       "      <td>0.361385</td>\n",
       "      <td>0.596547</td>\n",
       "      <td>0.149954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.191068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771975</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.505310</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.833510</td>\n",
       "      <td>0.469102</td>\n",
       "      <td>0.183767</td>\n",
       "      <td>0.211236</td>\n",
       "      <td>1.256863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47056</th>\n",
       "      <td>0.140682</td>\n",
       "      <td>0.360960</td>\n",
       "      <td>0.598227</td>\n",
       "      <td>0.151280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258709</td>\n",
       "      <td>0.191972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773590</td>\n",
       "      <td>0.501097</td>\n",
       "      <td>0.138832</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.146420</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>0.468087</td>\n",
       "      <td>0.183787</td>\n",
       "      <td>0.212318</td>\n",
       "      <td>1.253288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>0.150968</td>\n",
       "      <td>0.356283</td>\n",
       "      <td>0.616704</td>\n",
       "      <td>0.165866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257671</td>\n",
       "      <td>0.201917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791351</td>\n",
       "      <td>0.524584</td>\n",
       "      <td>0.151309</td>\n",
       "      <td>0.522132</td>\n",
       "      <td>0.151375</td>\n",
       "      <td>0.842988</td>\n",
       "      <td>0.456923</td>\n",
       "      <td>0.184008</td>\n",
       "      <td>0.224226</td>\n",
       "      <td>1.215896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47058</th>\n",
       "      <td>0.159383</td>\n",
       "      <td>0.352456</td>\n",
       "      <td>0.631822</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256822</td>\n",
       "      <td>0.210054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.543801</td>\n",
       "      <td>0.161516</td>\n",
       "      <td>0.534749</td>\n",
       "      <td>0.155429</td>\n",
       "      <td>0.850096</td>\n",
       "      <td>0.447789</td>\n",
       "      <td>0.184189</td>\n",
       "      <td>0.233968</td>\n",
       "      <td>1.187858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47059 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0      0.490075  0.586673  0.151645  0.417871  0.112102  0.634610  0.108587   \n",
       "1      0.501998  0.009768  0.302396  0.373206  0.250279  0.402819  0.539508   \n",
       "2      0.025338  0.000000  0.459353  0.000000  0.000000  0.008518  0.668628   \n",
       "3      0.119585  0.606693  0.365430  0.000000  0.000000  0.555020  0.058068   \n",
       "4      0.113869  0.567921  0.367087  0.000000  0.000000  0.540726  0.077600   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47054  0.465896  0.259782  0.823485  0.612409  0.270203  0.267166  0.260125   \n",
       "47055  0.139747  0.361385  0.596547  0.149954  0.000000  0.258803  0.191068   \n",
       "47056  0.140682  0.360960  0.598227  0.151280  0.000000  0.258709  0.191972   \n",
       "47057  0.150968  0.356283  0.616704  0.165866  0.000000  0.257671  0.201917   \n",
       "47058  0.159383  0.352456  0.631822  0.177800  0.000000  0.256822  0.210054   \n",
       "\n",
       "             x7        x8        x9  ...       x21       x22       x23  \\\n",
       "0      0.015170  0.263761  0.654423  ...  0.620409  0.000000  0.314657   \n",
       "1      0.594899  0.000000  0.392786  ...  0.602166  0.423305  0.627015   \n",
       "2      0.067823  0.000000  0.000000  ...  0.731785  0.581351  0.320759   \n",
       "3      0.000000  0.133846  0.000000  ...  0.524448  0.190185  0.221936   \n",
       "4      0.000000  0.112723  0.000000  ...  0.520300  0.206480  0.221795   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "47054  0.593737  0.075529  0.461807  ...  0.933103  0.877858  0.429925   \n",
       "47055  0.000000  0.000000  0.021274  ...  0.771975  0.498962  0.137698   \n",
       "47056  0.000000  0.000000  0.022390  ...  0.773590  0.501097  0.138832   \n",
       "47057  0.000000  0.000000  0.034670  ...  0.791351  0.524584  0.151309   \n",
       "47058  0.000000  0.000000  0.044717  ...  0.805882  0.543801  0.161516   \n",
       "\n",
       "            x24       x25       x26       x27       x28       x29     error  \n",
       "0      0.027900  0.654252  0.153930  0.975584  0.657599  0.305233  3.855455  \n",
       "1      0.470412  0.637579  0.205152  0.358128  0.513110  0.527753  2.230361  \n",
       "2      0.923884  0.128919  0.481807  0.229775  0.136514  0.203936  2.073030  \n",
       "3      0.405749  0.141641  0.963556  0.915166  0.502258  0.305077  1.785131  \n",
       "4      0.418604  0.127562  0.955616  0.891303  0.480094  0.308274  1.656335  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "47054  0.684466  0.519460  0.723924  0.046779  0.180541  0.501408  0.237799  \n",
       "47055  0.505310  0.145969  0.833510  0.469102  0.183767  0.211236  1.256863  \n",
       "47056  0.506712  0.146420  0.834300  0.468087  0.183787  0.212318  1.253288  \n",
       "47057  0.522132  0.151375  0.842988  0.456923  0.184008  0.224226  1.215896  \n",
       "47058  0.534749  0.155429  0.850096  0.447789  0.184189  0.233968  1.187858  \n",
       "\n",
       "[47059 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(x).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "columns = []\n",
    "\n",
    "for i in range(len(z[0])):\n",
    "    columns.append(\"x{}\".format(i))\n",
    "\n",
    "df_z = pd.DataFrame(z, columns=columns)\n",
    "\n",
    "# Normalize the data with MinMaxScaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "z_scaled = min_max_scaler.fit_transform(df_z.values)\n",
    "\n",
    "# Reassign to df_z\n",
    "df_z = pd.DataFrame(z_scaled, columns=columns)\n",
    "\n",
    "# Fetch the errors per data\n",
    "predictions = model(x)\n",
    "targets = x\n",
    "\n",
    "x_loss = nn.MSELoss(reduction='none')(predictions, targets).sum(axis=1).detach().cpu().numpy().astype(np.float32)\n",
    "df_z['error'] = x_loss\n",
    "\n",
    "df_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a0025",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Given the new dataset containing latent vectors and reconstruction error, we'll then perform clustering to form natural groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231dc4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [ -1   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16\n",
      "  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218]\n",
      "Count for Cluster -1: 5592\n",
      "Count for Cluster 0: 14\n",
      "Count for Cluster 1: 29\n",
      "Count for Cluster 2: 6\n",
      "Count for Cluster 3: 7\n",
      "Count for Cluster 4: 5\n",
      "Count for Cluster 5: 7\n",
      "Count for Cluster 6: 20\n",
      "Count for Cluster 7: 256\n",
      "Count for Cluster 8: 33261\n",
      "Count for Cluster 9: 408\n",
      "Count for Cluster 10: 116\n",
      "Count for Cluster 11: 297\n",
      "Count for Cluster 12: 154\n",
      "Count for Cluster 13: 94\n",
      "Count for Cluster 14: 16\n",
      "Count for Cluster 15: 22\n",
      "Count for Cluster 16: 210\n",
      "Count for Cluster 17: 6\n",
      "Count for Cluster 18: 1136\n",
      "Count for Cluster 19: 97\n",
      "Count for Cluster 20: 98\n",
      "Count for Cluster 21: 110\n",
      "Count for Cluster 22: 16\n",
      "Count for Cluster 23: 17\n",
      "Count for Cluster 24: 394\n",
      "Count for Cluster 25: 330\n",
      "Count for Cluster 26: 399\n",
      "Count for Cluster 27: 8\n",
      "Count for Cluster 28: 8\n",
      "Count for Cluster 29: 21\n",
      "Count for Cluster 30: 12\n",
      "Count for Cluster 31: 19\n",
      "Count for Cluster 32: 14\n",
      "Count for Cluster 33: 98\n",
      "Count for Cluster 34: 102\n",
      "Count for Cluster 35: 358\n",
      "Count for Cluster 36: 118\n",
      "Count for Cluster 37: 82\n",
      "Count for Cluster 38: 105\n",
      "Count for Cluster 39: 7\n",
      "Count for Cluster 40: 327\n",
      "Count for Cluster 41: 80\n",
      "Count for Cluster 42: 5\n",
      "Count for Cluster 43: 6\n",
      "Count for Cluster 44: 279\n",
      "Count for Cluster 45: 45\n",
      "Count for Cluster 46: 9\n",
      "Count for Cluster 47: 21\n",
      "Count for Cluster 48: 58\n",
      "Count for Cluster 49: 26\n",
      "Count for Cluster 50: 7\n",
      "Count for Cluster 51: 13\n",
      "Count for Cluster 52: 10\n",
      "Count for Cluster 53: 5\n",
      "Count for Cluster 54: 12\n",
      "Count for Cluster 55: 16\n",
      "Count for Cluster 56: 17\n",
      "Count for Cluster 57: 8\n",
      "Count for Cluster 58: 11\n",
      "Count for Cluster 59: 40\n",
      "Count for Cluster 60: 22\n",
      "Count for Cluster 61: 26\n",
      "Count for Cluster 62: 23\n",
      "Count for Cluster 63: 9\n",
      "Count for Cluster 64: 9\n",
      "Count for Cluster 65: 37\n",
      "Count for Cluster 66: 33\n",
      "Count for Cluster 67: 11\n",
      "Count for Cluster 68: 25\n",
      "Count for Cluster 69: 11\n",
      "Count for Cluster 70: 15\n",
      "Count for Cluster 71: 23\n",
      "Count for Cluster 72: 15\n",
      "Count for Cluster 73: 6\n",
      "Count for Cluster 74: 9\n",
      "Count for Cluster 75: 7\n",
      "Count for Cluster 76: 8\n",
      "Count for Cluster 77: 5\n",
      "Count for Cluster 78: 10\n",
      "Count for Cluster 79: 35\n",
      "Count for Cluster 80: 11\n",
      "Count for Cluster 81: 16\n",
      "Count for Cluster 82: 15\n",
      "Count for Cluster 83: 5\n",
      "Count for Cluster 84: 83\n",
      "Count for Cluster 85: 40\n",
      "Count for Cluster 86: 18\n",
      "Count for Cluster 87: 3\n",
      "Count for Cluster 88: 10\n",
      "Count for Cluster 89: 9\n",
      "Count for Cluster 90: 10\n",
      "Count for Cluster 91: 34\n",
      "Count for Cluster 92: 5\n",
      "Count for Cluster 93: 7\n",
      "Count for Cluster 94: 21\n",
      "Count for Cluster 95: 5\n",
      "Count for Cluster 96: 7\n",
      "Count for Cluster 97: 6\n",
      "Count for Cluster 98: 7\n",
      "Count for Cluster 99: 9\n",
      "Count for Cluster 100: 7\n",
      "Count for Cluster 101: 4\n",
      "Count for Cluster 102: 16\n",
      "Count for Cluster 103: 20\n",
      "Count for Cluster 104: 22\n",
      "Count for Cluster 105: 5\n",
      "Count for Cluster 106: 9\n",
      "Count for Cluster 107: 14\n",
      "Count for Cluster 108: 5\n",
      "Count for Cluster 109: 7\n",
      "Count for Cluster 110: 16\n",
      "Count for Cluster 111: 6\n",
      "Count for Cluster 112: 11\n",
      "Count for Cluster 113: 15\n",
      "Count for Cluster 114: 14\n",
      "Count for Cluster 115: 5\n",
      "Count for Cluster 116: 4\n",
      "Count for Cluster 117: 20\n",
      "Count for Cluster 118: 18\n",
      "Count for Cluster 119: 15\n",
      "Count for Cluster 120: 7\n",
      "Count for Cluster 121: 5\n",
      "Count for Cluster 122: 8\n",
      "Count for Cluster 123: 9\n",
      "Count for Cluster 124: 5\n",
      "Count for Cluster 125: 5\n",
      "Count for Cluster 126: 4\n",
      "Count for Cluster 127: 8\n",
      "Count for Cluster 128: 21\n",
      "Count for Cluster 129: 4\n",
      "Count for Cluster 130: 5\n",
      "Count for Cluster 131: 7\n",
      "Count for Cluster 132: 9\n",
      "Count for Cluster 133: 5\n",
      "Count for Cluster 134: 6\n",
      "Count for Cluster 135: 25\n",
      "Count for Cluster 136: 6\n",
      "Count for Cluster 137: 11\n",
      "Count for Cluster 138: 5\n",
      "Count for Cluster 139: 5\n",
      "Count for Cluster 140: 30\n",
      "Count for Cluster 141: 8\n",
      "Count for Cluster 142: 19\n",
      "Count for Cluster 143: 5\n",
      "Count for Cluster 144: 5\n",
      "Count for Cluster 145: 13\n",
      "Count for Cluster 146: 4\n",
      "Count for Cluster 147: 20\n",
      "Count for Cluster 148: 10\n",
      "Count for Cluster 149: 5\n",
      "Count for Cluster 150: 6\n",
      "Count for Cluster 151: 5\n",
      "Count for Cluster 152: 8\n",
      "Count for Cluster 153: 18\n",
      "Count for Cluster 154: 11\n",
      "Count for Cluster 155: 9\n",
      "Count for Cluster 156: 16\n",
      "Count for Cluster 157: 7\n",
      "Count for Cluster 158: 6\n",
      "Count for Cluster 159: 8\n",
      "Count for Cluster 160: 5\n",
      "Count for Cluster 161: 8\n",
      "Count for Cluster 162: 5\n",
      "Count for Cluster 163: 6\n",
      "Count for Cluster 164: 8\n",
      "Count for Cluster 165: 18\n",
      "Count for Cluster 166: 5\n",
      "Count for Cluster 167: 5\n",
      "Count for Cluster 168: 11\n",
      "Count for Cluster 169: 6\n",
      "Count for Cluster 170: 6\n",
      "Count for Cluster 171: 6\n",
      "Count for Cluster 172: 5\n",
      "Count for Cluster 173: 12\n",
      "Count for Cluster 174: 9\n",
      "Count for Cluster 175: 5\n",
      "Count for Cluster 176: 8\n",
      "Count for Cluster 177: 7\n",
      "Count for Cluster 178: 5\n",
      "Count for Cluster 179: 5\n",
      "Count for Cluster 180: 5\n",
      "Count for Cluster 181: 7\n",
      "Count for Cluster 182: 5\n",
      "Count for Cluster 183: 6\n",
      "Count for Cluster 184: 14\n",
      "Count for Cluster 185: 5\n",
      "Count for Cluster 186: 5\n",
      "Count for Cluster 187: 3\n",
      "Count for Cluster 188: 5\n",
      "Count for Cluster 189: 4\n",
      "Count for Cluster 190: 6\n",
      "Count for Cluster 191: 7\n",
      "Count for Cluster 192: 8\n",
      "Count for Cluster 193: 5\n",
      "Count for Cluster 194: 5\n",
      "Count for Cluster 195: 9\n",
      "Count for Cluster 196: 5\n",
      "Count for Cluster 197: 4\n",
      "Count for Cluster 198: 7\n",
      "Count for Cluster 199: 5\n",
      "Count for Cluster 200: 4\n",
      "Count for Cluster 201: 8\n",
      "Count for Cluster 202: 5\n",
      "Count for Cluster 203: 6\n",
      "Count for Cluster 204: 5\n",
      "Count for Cluster 205: 359\n",
      "Count for Cluster 206: 5\n",
      "Count for Cluster 207: 7\n",
      "Count for Cluster 208: 5\n",
      "Count for Cluster 209: 10\n",
      "Count for Cluster 210: 3\n",
      "Count for Cluster 211: 5\n",
      "Count for Cluster 212: 11\n",
      "Count for Cluster 213: 5\n",
      "Count for Cluster 214: 6\n",
      "Count for Cluster 215: 6\n",
      "Count for Cluster 216: 5\n",
      "Count for Cluster 217: 4\n",
      "Count for Cluster 218: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>error</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.490075</td>\n",
       "      <td>0.586673</td>\n",
       "      <td>0.151645</td>\n",
       "      <td>0.417871</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.634610</td>\n",
       "      <td>0.108587</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.263761</td>\n",
       "      <td>0.654423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314657</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.654252</td>\n",
       "      <td>0.153930</td>\n",
       "      <td>0.975584</td>\n",
       "      <td>0.657599</td>\n",
       "      <td>0.305233</td>\n",
       "      <td>3.855455</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501998</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.302396</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.402819</td>\n",
       "      <td>0.539508</td>\n",
       "      <td>0.594899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423305</td>\n",
       "      <td>0.627015</td>\n",
       "      <td>0.470412</td>\n",
       "      <td>0.637579</td>\n",
       "      <td>0.205152</td>\n",
       "      <td>0.358128</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.527753</td>\n",
       "      <td>2.230361</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.668628</td>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581351</td>\n",
       "      <td>0.320759</td>\n",
       "      <td>0.923884</td>\n",
       "      <td>0.128919</td>\n",
       "      <td>0.481807</td>\n",
       "      <td>0.229775</td>\n",
       "      <td>0.136514</td>\n",
       "      <td>0.203936</td>\n",
       "      <td>2.073030</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119585</td>\n",
       "      <td>0.606693</td>\n",
       "      <td>0.365430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555020</td>\n",
       "      <td>0.058068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190185</td>\n",
       "      <td>0.221936</td>\n",
       "      <td>0.405749</td>\n",
       "      <td>0.141641</td>\n",
       "      <td>0.963556</td>\n",
       "      <td>0.915166</td>\n",
       "      <td>0.502258</td>\n",
       "      <td>0.305077</td>\n",
       "      <td>1.785131</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113869</td>\n",
       "      <td>0.567921</td>\n",
       "      <td>0.367087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540726</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206480</td>\n",
       "      <td>0.221795</td>\n",
       "      <td>0.418604</td>\n",
       "      <td>0.127562</td>\n",
       "      <td>0.955616</td>\n",
       "      <td>0.891303</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.308274</td>\n",
       "      <td>1.656335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47054</th>\n",
       "      <td>0.465896</td>\n",
       "      <td>0.259782</td>\n",
       "      <td>0.823485</td>\n",
       "      <td>0.612409</td>\n",
       "      <td>0.270203</td>\n",
       "      <td>0.267166</td>\n",
       "      <td>0.260125</td>\n",
       "      <td>0.593737</td>\n",
       "      <td>0.075529</td>\n",
       "      <td>0.461807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877858</td>\n",
       "      <td>0.429925</td>\n",
       "      <td>0.684466</td>\n",
       "      <td>0.519460</td>\n",
       "      <td>0.723924</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.180541</td>\n",
       "      <td>0.501408</td>\n",
       "      <td>0.237799</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47055</th>\n",
       "      <td>0.139747</td>\n",
       "      <td>0.361385</td>\n",
       "      <td>0.596547</td>\n",
       "      <td>0.149954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.191068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.505310</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.833510</td>\n",
       "      <td>0.469102</td>\n",
       "      <td>0.183767</td>\n",
       "      <td>0.211236</td>\n",
       "      <td>1.256863</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47056</th>\n",
       "      <td>0.140682</td>\n",
       "      <td>0.360960</td>\n",
       "      <td>0.598227</td>\n",
       "      <td>0.151280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258709</td>\n",
       "      <td>0.191972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501097</td>\n",
       "      <td>0.138832</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.146420</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>0.468087</td>\n",
       "      <td>0.183787</td>\n",
       "      <td>0.212318</td>\n",
       "      <td>1.253288</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>0.150968</td>\n",
       "      <td>0.356283</td>\n",
       "      <td>0.616704</td>\n",
       "      <td>0.165866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257671</td>\n",
       "      <td>0.201917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524584</td>\n",
       "      <td>0.151309</td>\n",
       "      <td>0.522132</td>\n",
       "      <td>0.151375</td>\n",
       "      <td>0.842988</td>\n",
       "      <td>0.456923</td>\n",
       "      <td>0.184008</td>\n",
       "      <td>0.224226</td>\n",
       "      <td>1.215896</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47058</th>\n",
       "      <td>0.159383</td>\n",
       "      <td>0.352456</td>\n",
       "      <td>0.631822</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256822</td>\n",
       "      <td>0.210054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543801</td>\n",
       "      <td>0.161516</td>\n",
       "      <td>0.534749</td>\n",
       "      <td>0.155429</td>\n",
       "      <td>0.850096</td>\n",
       "      <td>0.447789</td>\n",
       "      <td>0.184189</td>\n",
       "      <td>0.233968</td>\n",
       "      <td>1.187858</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47059 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0      0.490075  0.586673  0.151645  0.417871  0.112102  0.634610  0.108587   \n",
       "1      0.501998  0.009768  0.302396  0.373206  0.250279  0.402819  0.539508   \n",
       "2      0.025338  0.000000  0.459353  0.000000  0.000000  0.008518  0.668628   \n",
       "3      0.119585  0.606693  0.365430  0.000000  0.000000  0.555020  0.058068   \n",
       "4      0.113869  0.567921  0.367087  0.000000  0.000000  0.540726  0.077600   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47054  0.465896  0.259782  0.823485  0.612409  0.270203  0.267166  0.260125   \n",
       "47055  0.139747  0.361385  0.596547  0.149954  0.000000  0.258803  0.191068   \n",
       "47056  0.140682  0.360960  0.598227  0.151280  0.000000  0.258709  0.191972   \n",
       "47057  0.150968  0.356283  0.616704  0.165866  0.000000  0.257671  0.201917   \n",
       "47058  0.159383  0.352456  0.631822  0.177800  0.000000  0.256822  0.210054   \n",
       "\n",
       "             x7        x8        x9  ...       x22       x23       x24  \\\n",
       "0      0.015170  0.263761  0.654423  ...  0.000000  0.314657  0.027900   \n",
       "1      0.594899  0.000000  0.392786  ...  0.423305  0.627015  0.470412   \n",
       "2      0.067823  0.000000  0.000000  ...  0.581351  0.320759  0.923884   \n",
       "3      0.000000  0.133846  0.000000  ...  0.190185  0.221936  0.405749   \n",
       "4      0.000000  0.112723  0.000000  ...  0.206480  0.221795  0.418604   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "47054  0.593737  0.075529  0.461807  ...  0.877858  0.429925  0.684466   \n",
       "47055  0.000000  0.000000  0.021274  ...  0.498962  0.137698  0.505310   \n",
       "47056  0.000000  0.000000  0.022390  ...  0.501097  0.138832  0.506712   \n",
       "47057  0.000000  0.000000  0.034670  ...  0.524584  0.151309  0.522132   \n",
       "47058  0.000000  0.000000  0.044717  ...  0.543801  0.161516  0.534749   \n",
       "\n",
       "            x25       x26       x27       x28       x29     error  \\\n",
       "0      0.654252  0.153930  0.975584  0.657599  0.305233  3.855455   \n",
       "1      0.637579  0.205152  0.358128  0.513110  0.527753  2.230361   \n",
       "2      0.128919  0.481807  0.229775  0.136514  0.203936  2.073030   \n",
       "3      0.141641  0.963556  0.915166  0.502258  0.305077  1.785131   \n",
       "4      0.127562  0.955616  0.891303  0.480094  0.308274  1.656335   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "47054  0.519460  0.723924  0.046779  0.180541  0.501408  0.237799   \n",
       "47055  0.145969  0.833510  0.469102  0.183767  0.211236  1.256863   \n",
       "47056  0.146420  0.834300  0.468087  0.183787  0.212318  1.253288   \n",
       "47057  0.151375  0.842988  0.456923  0.184008  0.224226  1.215896   \n",
       "47058  0.155429  0.850096  0.447789  0.184189  0.233968  1.187858   \n",
       "\n",
       "       cluster_label  \n",
       "0                 -1  \n",
       "1                 -1  \n",
       "2                 -1  \n",
       "3                 -1  \n",
       "4                  0  \n",
       "...              ...  \n",
       "47054             18  \n",
       "47055             20  \n",
       "47056             20  \n",
       "47057             20  \n",
       "47058             20  \n",
       "\n",
       "[47059 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(df_z.values)\n",
    "\n",
    "unique_labels = np.unique(clustering.labels_)\n",
    "\n",
    "print(\"Cluster labels: {}\".format(unique_labels))\n",
    "\n",
    "df_z_with_cluster_labels = df_z.copy()\n",
    "df_z_with_cluster_labels['cluster_label'] = clustering.labels_\n",
    "\n",
    "for cluster_label in unique_labels:\n",
    "    count = len(df_z_with_cluster_labels[df_z_with_cluster_labels['cluster_label'] == cluster_label])\n",
    "    print(\"Count for Cluster {}: {}\".format(cluster_label, count))\n",
    "    \n",
    "df_z_with_cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a25a26a",
   "metadata": {},
   "source": [
    "## Visualizing Clusters\n",
    "\n",
    "Use TSNE to reduce to 3 dimensions for visualization and plotly 3d scatterplot for visualization.\n",
    "\n",
    "**Documentation:**\n",
    "* **TSNE:**: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "* **Plotly 3D Scatterplot:**: https://plotly.com/python/3d-scatter-plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19baac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a TSNE model with 3 dimensions\n",
    "# z_embedded = TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df_z.values)\n",
    "\n",
    "# # Create a new data frame for result of tsne and attach cluster label\n",
    "# df_z_embedded = pd.DataFrame(z_embedded, columns=['x', 'y', 'z'])\n",
    "# df_z_embedded['cluster_label'] = df_z_with_cluster_labels['cluster_label']\n",
    "\n",
    "# # Visualize with 3D scatterplot\n",
    "# fig = px.scatter_3d(df_z_embedded, x='x', y='y', z='z', color='cluster_label')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e648b20",
   "metadata": {},
   "source": [
    "## Training for Perceived Normal Data\n",
    "\n",
    "We now train a new autoencoder model for data points whose cluster_label is not equal to -1. This will serve as our prediction model for auto-thresholding later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febcadad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47054</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484582</td>\n",
       "      <td>0.255578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47055</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47056</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47058</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41467 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x0        x1        x2   x3        x4        x5        x6   x7   x8  \\\n",
       "4      0.0  1.000000  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0   \n",
       "5      0.0  1.000000  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0   \n",
       "6      0.0  1.000000  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0   \n",
       "8      0.0  1.000000  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0   \n",
       "9      0.0  1.000000  0.514821  0.0  0.000235  0.000000  0.333333  0.0  0.0   \n",
       "...    ...       ...       ...  ...       ...       ...       ...  ...  ...   \n",
       "47054  0.0  0.484582  0.255578  0.0  0.000007  0.000025  0.000000  0.0  0.0   \n",
       "47055  0.0  1.000000  0.514821  0.0  0.000005  0.000000  0.000000  0.0  0.0   \n",
       "47056  0.0  1.000000  0.514821  0.0  0.000005  0.000000  0.000000  0.0  0.0   \n",
       "47057  0.0  1.000000  0.514821  0.0  0.000005  0.000000  0.000000  0.0  0.0   \n",
       "47058  0.0  1.000000  0.514821  0.0  0.000005  0.000000  0.000000  0.0  0.0   \n",
       "\n",
       "        x9  ...       x30       x31  x32  x33  x34   x35  x36  x37  x38  x39  \n",
       "4      0.0  ...  0.003922  0.027451  1.0  0.0  1.0  0.57  0.0  0.0  0.0  0.0  \n",
       "5      0.0  ...  0.003922  0.035294  1.0  0.0  1.0  0.56  0.0  0.0  0.0  0.0  \n",
       "6      0.0  ...  0.003922  0.043137  1.0  0.0  1.0  0.55  0.0  0.0  0.0  0.0  \n",
       "8      0.0  ...  0.003922  0.050980  1.0  0.0  1.0  0.54  0.0  0.0  0.0  0.0  \n",
       "9      0.0  ...  0.003922  0.066667  1.0  0.0  1.0  0.53  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...       ...       ...  ...  ...  ...   ...  ...  ...  ...  ...  \n",
       "47054  0.0  ...  1.000000  1.000000  1.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  \n",
       "47055  0.0  ...  0.215686  0.215686  1.0  0.0  1.0  0.00  0.0  0.0  0.0  0.0  \n",
       "47056  0.0  ...  0.219608  0.219608  1.0  0.0  1.0  0.00  0.0  0.0  0.0  0.0  \n",
       "47057  0.0  ...  0.262745  0.262745  1.0  0.0  1.0  0.00  0.0  0.0  0.0  0.0  \n",
       "47058  0.0  ...  0.298039  0.298039  1.0  0.0  1.0  0.00  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[41467 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal = df_train_x.copy()\n",
    "df_normal = df_normal[df_z_with_cluster_labels['cluster_label'] != -1]\n",
    "\n",
    "df_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbfde6",
   "metadata": {},
   "source": [
    "## Represent the training data as x\n",
    "x = torch.tensor(df_normal.values).float().to(device)\n",
    "\n",
    "# Load the dataset\n",
    "train_ds = AutoencoderDataset(x=x)\n",
    "\n",
    "# Create a DataLoader instance\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# The training process\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    loop = tqdm(train_loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Feed forward\n",
    "        predictions = model(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408253f",
   "metadata": {},
   "source": [
    "## Threshold Computation\n",
    "\n",
    "Using reconstruction errors, compute for the reconstruction threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49279f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASWUlEQVR4nO3df4xd5X3n8fenODQVbWNTZi3LttZI9aZKVwphR0CUqtoNijE0ivkjRUS7YYS88v5BV8nuSl3Yf7yFRpv+U7dIWyQreNd0s6Fu0ggri0JHDlUVafkxDoQEHPCUBtkW4GnGkGZRU5F+94953FzMDHMHX8945nm/pKt7zvc855znkeXPOXruuXdSVUiS+vAzK90BSdLyMfQlqSOGviR1xNCXpI4Y+pLUkXUr3YF3csUVV9S2bdtWuhuStKocPXr0b6pqbL5tF3Xob9u2jampqZXuhiStKkleWmib0zuS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHVk09JO8P8nTA68fJvlsksuTTCY53t43tPZJcm+S6STPJLl64FgTrf3xJBMXcmCSpLdbNPSr6vmquqqqrgL+BfAG8FXgTuBIVW0HjrR1gBuB7e21B7gPIMnlwF7gWuAaYO/ZC4UkaXksdXrneuCvquolYBdwsNUPAje35V3AAzXnMWB9kk3ADcBkVc1W1RlgEth5vgOQJA1vqaF/K/Cltryxql5uy68AG9vyZuDEwD4nW22h+lsk2ZNkKsnUzMzMErsnSXonQ4d+kkuBTwB/eu62qiqgRtGhqtpfVeNVNT42NjaKQ0qSmqXc6d8IfKuqXm3rr7ZpG9r76VY/BWwd2G9Lqy1UlyQtk6WE/qf46dQOwGHg7BM4E8BDA/Xb2lM81wGvt2mgR4AdSTa0D3B3tJokaZmsG6ZRksuAjwH/bqD8eeBQkt3AS8Atrf4wcBMwzdyTPrcDVNVsknuAJ1u7u6tq9rxHIEkaWuam4y9O4+PjNTU1tdLdkKRVJcnRqhqfb5vfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGhQj/J+iRfTvK9JMeSfDjJ5Ukmkxxv7xta2yS5N8l0kmeSXD1wnInW/niSiYXPKEm6EIa90/9D4OtV9SvAB4FjwJ3AkaraDhxp6wA3Atvbaw9wH0CSy4G9wLXANcDesxcKSdLyWDT0k7wP+HXgfoCq+vuqeg3YBRxszQ4CN7flXcADNecxYH2STcANwGRVzVbVGWAS2DnCsUiSFjHMnf6VwAzwP5I8leQLSS4DNlbVy63NK8DGtrwZODGw/8lWW6guSVomw4T+OuBq4L6q+hDw//jpVA4AVVVAjaJDSfYkmUoyNTMzM4pDSpKaYUL/JHCyqh5v619m7iLwapu2ob2fbttPAVsH9t/SagvV36Kq9lfVeFWNj42NLWUskqRFLBr6VfUKcCLJ+1vpeuA54DBw9gmcCeChtnwYuK09xXMd8HqbBnoE2JFkQ/sAd0erSZKWyboh2/174ItJLgVeBG5n7oJxKMlu4CXgltb2YeAmYBp4o7WlqmaT3AM82drdXVWzIxmFJGkomZuOvziNj4/X1NTUSndDklaVJEerany+bX4jV5I6YuhLUkfWfOjvm3xhpbsgSReNNR/6kqSfMvQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyFChn+T7Sb6T5OkkU612eZLJJMfb+4ZWT5J7k0wneSbJ1QPHmWjtjyeZuDBDkiQtZCl3+v+qqq4a+GO7dwJHqmo7cKStA9wIbG+vPcB9MHeRAPYC1wLXAHvPXigkScvjfKZ3dgEH2/JB4OaB+gM15zFgfZJNwA3AZFXNVtUZYBLYeR7nlyQt0bChX8CfJzmaZE+rbayql9vyK8DGtrwZODGw78lWW6j+Fkn2JJlKMjUzMzNk9yRJw1g3ZLtfq6pTSf4JMJnke4Mbq6qS1Cg6VFX7gf0A4+PjIzmmJGnOUHf6VXWqvZ8GvsrcnPyrbdqG9n66NT8FbB3YfUurLVSXJC2TRUM/yWVJfuHsMrAD+C5wGDj7BM4E8FBbPgzc1p7iuQ54vU0DPQLsSLKhfYC7o9UkSctkmOmdjcBXk5xt/7+r6utJngQOJdkNvATc0to/DNwETANvALcDVNVsknuAJ1u7u6tqdmQjkSQtatHQr6oXgQ/OU/8BcP089QLuWOBYB4ADS++mJGkU/EauJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SODB36SS5J8lSSr7X1K5M8nmQ6yZ8kubTVf7atT7ft2waOcVerP5/khpGPRpL0jpZyp/8Z4NjA+u8B+6rql4EzwO5W3w2cafV9rR1JPgDcCvwqsBP4oySXnF/3JUlLMVToJ9kC/AbwhbYe4KPAl1uTg8DNbXlXW6dtv7613wU8WFU/rqq/BqaBa0YwBknSkIa90/8D4LeBf2jrvwS8VlVvtvWTwOa2vBk4AdC2v97a/2N9nn3+UZI9SaaSTM3MzAw/EknSohYN/SQfB05X1dFl6A9Vtb+qxqtqfGxsbDlOKUndWDdEm48An0hyE/Be4BeBPwTWJ1nX7ua3AKda+1PAVuBkknXA+4AfDNTPGtxHkrQMFr3Tr6q7qmpLVW1j7oPYb1TVvwYeBT7Zmk0AD7Xlw22dtv0bVVWtfmt7uudKYDvwxMhGIkla1DB3+gv5z8CDSX4XeAq4v9XvB/44yTQwy9yFgqp6Nskh4DngTeCOqvrJeZxfkrRESwr9qvoL4C/a8ovM8/RNVf0d8JsL7P854HNL7aQkaTT8Rq4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkUVDP8l7kzyR5NtJnk3yO61+ZZLHk0wn+ZMkl7b6z7b16bZ928Cx7mr155PccMFGJUma1zB3+j8GPlpVHwSuAnYmuQ74PWBfVf0ycAbY3drvBs60+r7WjiQfAG4FfhXYCfxRkktGOBZJ0iIWDf2a86O2+p72KuCjwJdb/SBwc1ve1dZp269PklZ/sKp+XFV/DUwD14xiEJKk4Qw1p5/kkiRPA6eBSeCvgNeq6s3W5CSwuS1vBk4AtO2vA780WJ9nn8Fz7UkylWRqZmZmyQOSJC1sqNCvqp9U1VXAFubuzn/lQnWoqvZX1XhVjY+NjV2o00hSl5b09E5VvQY8CnwYWJ9kXdu0BTjVlk8BWwHa9vcBPxisz7OPJGkZDPP0zliS9W3554CPAceYC/9PtmYTwENt+XBbp23/RlVVq9/anu65EtgOPDGicUiShrBu8SZsAg62J21+BjhUVV9L8hzwYJLfBZ4C7m/t7wf+OMk0MMvcEztU1bNJDgHPAW8Cd1TVT0Y7HEnSO1k09KvqGeBD89RfZJ6nb6rq74DfXOBYnwM+t/RuSpJGwW/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyDB/GH1rkkeTPJfk2SSfafXLk0wmOd7eN7R6ktybZDrJM0muHjjWRGt/PMnEQueUJF0Yw9zpvwn8p6r6AHAdcEeSDwB3AkeqajtwpK0D3Ahsb689wH0wd5EA9gLXMve3dfeevVBIkpbHoqFfVS9X1bfa8t8Cx4DNwC7gYGt2ELi5Le8CHqg5jwHrk2wCbgAmq2q2qs4Ak8DOUQ5GkvTOljSnn2Qb8CHgcWBjVb3cNr0CbGzLm4ETA7udbLWF6ueeY0+SqSRTMzMzS+meJGkRQ4d+kp8HvgJ8tqp+OLitqgqoUXSoqvZX1XhVjY+NjY3ikJKkZqjQT/Ie5gL/i1X1Z638apu2ob2fbvVTwNaB3be02kJ1SdIyGebpnQD3A8eq6vcHNh0Gzj6BMwE8NFC/rT3Fcx3wepsGegTYkWRD+wB3R6tJkpbJuiHafAT4NPCdJE+32n8BPg8cSrIbeAm4pW17GLgJmAbeAG4HqKrZJPcAT7Z2d1fV7CgGIUkazqKhX1XfBLLA5uvnaV/AHQsc6wBwYCkdlCSNjt/IlaSOrOnQ3zf5wlveJal3azr0JUlvZehLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkWH+MPqBJKeTfHegdnmSySTH2/uGVk+Se5NMJ3kmydUD+0y09seTTMx3LknShTXMnf7/BHaeU7sTOFJV24EjbR3gRmB7e+0B7oO5iwSwF7gWuAbYe/ZCIUlaPouGflX9JTB7TnkXcLAtHwRuHqg/UHMeA9Yn2QTcAExW1WxVnQEmefuFRJJ0gb3bOf2NVfVyW34F2NiWNwMnBtqdbLWF6m+TZE+SqSRTMzMz77J7kqT5nPcHuVVVQI2gL2ePt7+qxqtqfGxsbFSHlSTx7kP/1TZtQ3s/3eqngK0D7ba02kJ1SdIyerehfxg4+wTOBPDQQP229hTPdcDrbRroEWBHkg3tA9wdrSZJWkbrFmuQ5EvAvwSuSHKSuadwPg8cSrIbeAm4pTV/GLgJmAbeAG4HqKrZJPcAT7Z2d1fVuR8OS5IusEVDv6o+tcCm6+dpW8AdCxznAHBgSb2TJI2U38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakj3YT+vskXVroLkrTiugl9SZKhL0ld6Sr0902+4DSPpK51FfqS1DtDX5I6Yug3TvtI6oGhL0kdMfTP4R2/pLXM0JekjnQZ+gvdzXuXL2mt6zL04acBv9iz+14IJK0lyx76SXYmeT7JdJI7l/v8gxa74zfwJa01i/5h9FFKcgnw34GPASeBJ5McrqrnlrMfwxgM/LPL/+Fj/2ze7WcNbj93v32TL7xt+7lt32m7JI1Cqmr5TpZ8GPivVXVDW78LoKr+23ztx8fHa2pq6l2fby3fqQ9eSIa9YIy63YUweO5zxzffxVfS2yU5WlXj825b5tD/JLCzqv5tW/80cG1V/dZAmz3Anrb6fuD5d3m6K4C/OY/uXswc2+rk2Faf1Tquf1pVY/NtWNbpnWFU1X5g//keJ8nUQle61c6xrU6ObfVZi+Na7g9yTwFbB9a3tJokaRksd+g/CWxPcmWSS4FbgcPL3AdJ6tayTu9U1ZtJfgt4BLgEOFBVz16g0533FNFFzLGtTo5t9Vlz41rWD3IlSSur22/kSlKPDH1J6siaDP2L6aceRinJgSSnk3x3pfsyakm2Jnk0yXNJnk3ymZXu0ygkeW+SJ5J8u43rd1a6T6OW5JIkTyX52kr3ZZSSfD/Jd5I8neTdf0v0IrPm5vTbTz28wMBPPQCfuhh/6mGpkvw68CPggar65yvdn1FKsgnYVFXfSvILwFHg5tX+75YkwGVV9aMk7wG+CXymqh5b4a6NTJL/CIwDv1hVH1/p/oxKku8D41W1Gr+ctaC1eKd/DTBdVS9W1d8DDwK7VrhPI1FVfwnMrnQ/LoSqermqvtWW/xY4Bmxe2V6dv5rzo7b6nvZaM3daSbYAvwF8YaX7ouGsxdDfDJwYWD/JGgiPniTZBnwIeHyFuzISbfrjaeA0MFlVa2JczR8Avw38wwr340Io4M+THG0/D7MmrMXQ1yqW5OeBrwCfraofrnR/RqGqflJVVzH3DfRrkqyJqbkkHwdOV9XRle7LBfJrVXU1cCNwR5teXfXWYuj7Uw+rVJvz/grwxar6s5Xuz6hV1WvAo8DOFe7KqHwE+ESb+34Q+GiS/7WyXRqdqjrV3k8DX2Vu6njVW4uh7089rELtA8/7gWNV9fsr3Z9RSTKWZH1b/jnmHjD43op2akSq6q6q2lJV25j7f/aNqvo3K9ytkUhyWXuggCSXATuANfHU3JoL/ap6Ezj7Uw/HgEMX8KcellWSLwH/F3h/kpNJdq90n0boI8CnmbtbfLq9blrpTo3AJuDRJM8wd0MyWVVr6tHGNWoj8M0k3waeAP5PVX19hfs0EmvukU1J0sLW3J2+JGlhhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyP8HjKd+i7K6m7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin Width: 0.005688386574960179\n",
      "Num Bins: 976\n",
      "Max Loss: 5.558133125305176\n",
      "Min Loss: 0.003222566330805421\n",
      "Min Bin: 0.003222566330805421\n",
      "Max Bin: 5.5613555908203125\n",
      "Optimal Threshold: 0.6040248662485268\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Utility Functions\n",
    "\"\"\"\n",
    "# Head tail break function\n",
    "def htb(data):\n",
    "    outp = []\n",
    "    \n",
    "    def htb_inner(data):\n",
    "        data_length = float(len(data))\n",
    "        data_mean = sum(data) / data_length\n",
    "        \n",
    "        head = [_ for _ in data if _ > data_mean]\n",
    "        outp.append(data_mean)\n",
    "        \n",
    "        while len(head) > 1 and len(head) / data_length < 0.40:\n",
    "            return htb_inner(head)\n",
    "        \n",
    "    htb_inner(data)\n",
    "    \n",
    "    return outp\n",
    "\n",
    "# Determine a breakpoint\n",
    "def fetch_threshold(bins, counts, break_point):\n",
    "    index = 0\n",
    "    latest_min = 999999\n",
    "    threshold = -1\n",
    "    \n",
    "    for i in range(len(counts)):\n",
    "        diff = abs(counts[i] - break_point)\n",
    "        \n",
    "        if diff <= latest_min:\n",
    "            latest_min = diff\n",
    "            index = i\n",
    "            threshold = ((bins[i + 1] - bins[i]) / 2) + bins[i]\n",
    "            \n",
    "    return threshold\n",
    "\n",
    "predictions = model(x)\n",
    "targets = x\n",
    "\n",
    "x_loss = nn.MSELoss(reduction='none')(predictions, targets).sum(axis=1).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "max_loss = np.max(x_loss)\n",
    "min_loss = np.min(x_loss)\n",
    "\n",
    "# Compute the optimal bin width using Freedman Diaconis rule\n",
    "bin_width = 2 * (iqr(x_loss) / (len(x_loss) ** (1./3)))\n",
    "num_bins = int((max_loss - min_loss) / bin_width)\n",
    "\n",
    "# Create the histogram\n",
    "min_bin = np.min(x_loss)\n",
    "max_bin = np.max(x_loss) + min_bin\n",
    "\n",
    "step = (max_bin - min_bin) / num_bins\n",
    "\n",
    "bins = np.arange(min_bin, max_bin, step)\n",
    "\n",
    "hist, bins = np.histogram(x_loss, bins=bins)\n",
    "\n",
    "pyplot.hist(x_loss, bins, alpha=0.5)\n",
    "pyplot.show()\n",
    "\n",
    "print(\"Bin Width: {}\".format(bin_width))\n",
    "print(\"Num Bins: {}\".format(num_bins))\n",
    "print(\"Max Loss: {}\".format(max_loss))\n",
    "print(\"Min Loss: {}\".format(min_loss))\n",
    "print(\"Min Bin: {}\".format(min_bin))\n",
    "print(\"Max Bin: {}\".format(max_bin))\n",
    "\n",
    "\n",
    "\n",
    "# Determine breaks\n",
    "breaks = htb(hist)\n",
    "\n",
    "possible_thresholds = []\n",
    "\n",
    "for b in breaks:\n",
    "    t = fetch_threshold(bins, hist, b)\n",
    "    possible_thresholds.append(t)\n",
    "\n",
    "optimal_threshold = max(possible_thresholds)\n",
    "\n",
    "print(\"Optimal Threshold: {}\".format(optimal_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac907864",
   "metadata": {},
   "source": [
    "## Compute for Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bddfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.593385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0   x1        x2        x3        x4        x5        x6  \\\n",
       "0     0.000000  0.0  0.000000  0.000000  0.000030  0.000057  0.000000   \n",
       "1     0.000000  0.0  0.000000  0.000000  0.000045  0.001331  0.000000   \n",
       "2     0.000000  0.0  0.000000  0.000000  0.000036  0.004719  0.000000   \n",
       "3     0.000000  0.0  0.000000  0.000000  0.000035  0.001277  0.000000   \n",
       "4     0.000000  0.0  0.000000  0.000000  0.000041  0.001326  0.000000   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "1045  0.000000  0.0  0.335534  0.593385  0.000000  0.000000  0.000000   \n",
       "1046  0.000000  0.0  1.000000  0.593385  0.000000  0.000000  0.000000   \n",
       "1047  0.000000  0.0  0.335534  0.593385  0.000000  0.000000  0.000000   \n",
       "1048  0.000000  1.0  0.514821  0.000000  0.000235  0.000000  0.333333   \n",
       "1049  0.000477  0.0  1.000000  0.000000  0.000014  0.000576  0.000000   \n",
       "\n",
       "            x7   x8   x9  ...       x31   x32   x33   x34   x35   x36  x37  \\\n",
       "0     0.000000  0.0  0.0  ...  1.000000  1.00  0.00  0.00  0.00  0.00  0.0   \n",
       "1     0.000000  0.0  0.0  ...  1.000000  1.00  0.00  0.00  0.01  0.00  0.0   \n",
       "2     0.000000  0.0  0.0  ...  1.000000  1.00  0.00  0.00  0.00  0.00  0.0   \n",
       "3     0.000000  0.0  0.0  ...  1.000000  1.00  0.00  0.06  0.02  0.00  0.0   \n",
       "4     0.000000  0.0  0.0  ...  1.000000  1.00  0.00  0.00  0.00  0.00  0.0   \n",
       "...        ...  ...  ...  ...       ...   ...   ...   ...   ...   ...  ...   \n",
       "1045  0.000000  0.0  0.0  ...  0.003922  0.01  1.00  1.00  0.00  1.00  1.0   \n",
       "1046  0.000000  0.0  0.0  ...  0.011765  0.01  1.00  1.00  0.67  1.00  1.0   \n",
       "1047  0.000000  0.0  0.0  ...  0.003922  0.03  1.00  1.00  0.00  1.00  1.0   \n",
       "1048  0.000000  0.0  0.0  ...  0.027451  0.50  1.00  0.50  0.57  0.50  0.0   \n",
       "1049  0.333333  0.0  0.0  ...  0.003922  0.00  0.03  0.00  0.00  0.51  0.0   \n",
       "\n",
       "       x38  x39  y  \n",
       "0     0.00  0.0  1  \n",
       "1     0.00  0.0  1  \n",
       "2     0.00  0.0  1  \n",
       "3     0.00  0.0  1  \n",
       "4     0.00  0.0  1  \n",
       "...    ...  ... ..  \n",
       "1045  0.00  0.0 -1  \n",
       "1046  0.00  0.0 -1  \n",
       "1047  0.00  0.0 -1  \n",
       "1048  0.00  0.0 -1  \n",
       "1049  0.02  0.0 -1  \n",
       "\n",
       "[1050 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to tensor\n",
    "x = torch.tensor(df_test_x.values).float().to(device)\n",
    "\n",
    "predictions = model(x)\n",
    "targets = x\n",
    "\n",
    "# Get reconstruction error\n",
    "x_loss = nn.MSELoss(reduction='none')(predictions, targets).sum(axis=1).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "# If reconstruction error is >= than the optimal threshold, we consider it an anomaly\n",
    "bool_arr = x_loss >= optimal_threshold\n",
    "\n",
    "# Convert anomaly labels to -1 if True and 1 if False\n",
    "anomaly_predictions = np.array([-1 if elem else 1 for elem in bool_arr])\n",
    "\n",
    "# Build dataframe for test data and attach predictions\n",
    "df_test_x_with_labels = df_test_x.copy()\n",
    "df_test_x_with_labels['y'] = anomaly_predictions\n",
    "\n",
    "df_test_x_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c57564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a TSNE model with 3 dimensions\n",
    "# z_embedded = TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df_test_x_with_labels.drop(columns=['y'], axis=1).values)\n",
    "\n",
    "# # Create a new data frame for result of tsne and attach cluster label\n",
    "# df_z_embedded = pd.DataFrame(z_embedded, columns=['x', 'y', 'z'])\n",
    "# df_z_embedded['y'] = anomaly_predictions\n",
    "\n",
    "# # Visualize with 3D scatterplot\n",
    "# fig = px.scatter_3d(df_z_embedded, x='x', y='y', z='z', color='y')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0bac8",
   "metadata": {},
   "source": [
    "## Evaluation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7f979ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 905\n",
      "True Negative: 50\n",
      "False Positive: 0\n",
      "False Negative: 95\n",
      "F1: 0.9501312335958005\n"
     ]
    }
   ],
   "source": [
    "ground_truth = np.array([1 if elem == 1 else -1 for elem in df_test_y.values])\n",
    "\n",
    "y_truth = np.array([0 if elem == -1 else 1 for elem in ground_truth])\n",
    "y_predictions = np.array([0 if elem == -1 else 1 for elem in anomaly_predictions])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(ground_truth, anomaly_predictions).ravel()\n",
    "tn, fp, fn, tp = confusion_matrix(y_truth, y_predictions).ravel()\n",
    "\n",
    "f1 = tp / (tp + 0.5* (fp + fn))\n",
    "\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"F1: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fa6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(y, bool_a, errors, threshold, max_err):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if bool_a[i]:\n",
    "            prob_anomaly = 0.5 + (1 - (threshold / x_loss[i]))\n",
    "            \n",
    "            if prob_anomaly > 1:\n",
    "                prob_anomaly = 0.99\n",
    "                \n",
    "            prob_normal = 1 - prob_anomaly\n",
    "                \n",
    "            results.append([prob_normal, prob_anomaly])\n",
    "        else:\n",
    "            prob_normal = 0.5 + (1 - (x_loss[i] / threshold))\n",
    "            \n",
    "            if prob_normal > 1:\n",
    "                prob_normal = 0.99\n",
    "            \n",
    "            prob_anomaly = 1 - prob_normal\n",
    "            \n",
    "            results.append([prob_normal, prob_anomaly])\n",
    "    \n",
    "    return results\n",
    "\n",
    "y_probs = predict_proba(y_truth, bool_arr, x_loss, optimal_threshold, np.max(x_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95bbbd",
   "metadata": {},
   "source": [
    "## ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616f05c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.984500 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def mapper(arr):\n",
    "    return arr[0]\n",
    "\n",
    "probabilities = list(map(mapper, y_probs))\n",
    "# print(probabilities)\n",
    "\n",
    "auc = roc_auc_score(y_truth, probabilities)\n",
    "print('ROC AUC: %f' % auc, '\\n')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_truth, probabilities)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f)\" % auc,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
