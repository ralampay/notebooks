{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086545a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=2, kernel_size=3, max_pool_kernel_size=2):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.max_pool_kernel_size = max_pool_kernel_size\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=self.kernel_size)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=self.kernel_size)\n",
    "        \n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = self.max_pool_kernel_size, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=self.kernel_size)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=self.kernel_size)\n",
    "        \n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = self.max_pool_kernel_size, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        \n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        \n",
    "        out = self.max_pool2(out)\n",
    "        \n",
    "        # Flatten things out\n",
    "        # out = out.reshape(out.shape(0), -1)\n",
    "        out = out.view(-1, 1600)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDataset(Dataset):\n",
    "    def __init__(self, img_dir, img_width, img_height, label):\n",
    "        self.img_dir    = img_dir\n",
    "        self.img_width  = img_width\n",
    "        self.img_height = img_height\n",
    "        self.images     = os.listdir(img_dir)\n",
    "        self.label      = label\n",
    "\n",
    "        self.dim = (img_width, img_height)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.images[index])\n",
    "\n",
    "        img = (cv2.resize(cv2.imread(img_path), self.dim) / 255).transpose((2, 0, 1)) \n",
    "\n",
    "        # Input is the Output\n",
    "        output = torch.Tensor(img), torch.Tensor(self.label)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data    = data.float().to(device=device)\n",
    "        targets = targets.float().to(device=device)\n",
    "\n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "    ave_loss = ave_loss / count\n",
    "\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c959784",
   "metadata": {},
   "outputs": [],
   "source": [
    "device         = 'cuda'\n",
    "gpu_index      = 0\n",
    "epochs         = 10\n",
    "learning_rate  = 0.0001\n",
    "chunk_size     = 1\n",
    "batch_size     = 1\n",
    "cont           = True\n",
    "model_file     = \"cnn-model.pth\"\n",
    "padding        = 1\n",
    "scale          = 2\n",
    "img_width      = 32\n",
    "img_height     = 32\n",
    "train_img_dir  = \"/home/ralampay/Desktop/Female\"\n",
    "label          = [1,0]\n",
    "num_channels   = 3\n",
    "\n",
    "# CNN Parameters\n",
    "num_classes          = 2\n",
    "kernel_size          = 3\n",
    "max_pool_kernel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    print(\"CUDA Device: {}\".format(torch.cuda.get_device_name(gpu_index)))\n",
    "    device = \"cuda:{}\".format(gpu_index)\n",
    "\n",
    "model = ConvolutionalNeuralNetwork(\n",
    "    num_classes=num_classes, \n",
    "    kernel_size=kernel_size, \n",
    "    max_pool_kernel_size=max_pool_kernel_size\n",
    ").to(device)\n",
    "\n",
    "if cont:\n",
    "    print(\"Loading model from {}\".format(model_file))\n",
    "    state = torch.load(model_file)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    model.optimizer = state['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ccc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6616247",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CnnDataset(\n",
    "    img_dir=train_img_dir,\n",
    "    img_width=img_width,\n",
    "    img_height=img_height,\n",
    "    label=label\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5729d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    ave_loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "\n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    losses.append(ave_loss)\n",
    "\n",
    "    # Save model after every epoch\n",
    "    print(\"Saving model to {}...\".format(model_file))\n",
    "\n",
    "    state = {\n",
    "        'state_dict':   model.state_dict(),\n",
    "        'optimizer':    optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(state, model_file)\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3a57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
